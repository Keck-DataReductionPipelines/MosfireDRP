{
    "docs": [
        {
            "location": "/",
            "text": "MOSFIRE DRP\n\n\nThis is the central repository for the MOSFIRE DRP originally developed by N. Konidaris and C. Steidel at Caltech, and currently hosted at the W.M. Keck Observatory.\n\n\nIf you need help with the pipeline or to report a problem, please visit our \nissue tracking page\n hosted at GitHub. Please note that you need a free GitHub account to submit a ticket.\n\n\nThe currently released installation and reduction instructions are provided in the \nDRP manual\n.\n\n\nThe support team currently includes: Luca Rizzi, Josh Walawender, Jim Lyke, Marc Kassis (W. M. Keck Observatory), Leo Alcorn (Texas A&M University), Chuck Steidel (Caltech), and Tuan Do (UCLA).",
            "title": "Home"
        },
        {
            "location": "/#mosfire-drp",
            "text": "This is the central repository for the MOSFIRE DRP originally developed by N. Konidaris and C. Steidel at Caltech, and currently hosted at the W.M. Keck Observatory.  If you need help with the pipeline or to report a problem, please visit our  issue tracking page  hosted at GitHub. Please note that you need a free GitHub account to submit a ticket.  The currently released installation and reduction instructions are provided in the  DRP manual .  The support team currently includes: Luca Rizzi, Josh Walawender, Jim Lyke, Marc Kassis (W. M. Keck Observatory), Leo Alcorn (Texas A&M University), Chuck Steidel (Caltech), and Tuan Do (UCLA).",
            "title": "MOSFIRE DRP"
        },
        {
            "location": "/manual/",
            "text": "Table of Contents\n\n\n\n\nLatest Changes\n\n\nPreface\n\n\nInstalling the Data Reduction Pipeline\n\n\nRetrieve Your Data\n\n\nDRP First Reduction Step: Handle\n\n\nAutomatic Generation of the Driver File\n\n\nThe driver.py File\n\n\nFlats\n\n\nWavelength Calibration \u2013 Y, J, and H Bands\n\n\nWavelength Calibration \u2013 K Band\n\n\nBackground Subtraction\n\n\nRectify\n\n\nSpectral Extraction\n\n\nLong2pos Reductions\n\n\nLongslit Reductions\n\n\nA Word About Header Comments\n\n\nSome Hints\n\n\n\n\nThe manual is also available in pdf form: \nMOSFIRE_DRP_Manual.pdf\n\n\n\nNote: pdf version of the manual is generated from the individual markdown files for each section by running the \ngenerate_pdf\n script in the \ndocs/\n subdirectory of this repository.",
            "title": "Contents"
        },
        {
            "location": "/manual/#table-of-contents",
            "text": "Latest Changes  Preface  Installing the Data Reduction Pipeline  Retrieve Your Data  DRP First Reduction Step: Handle  Automatic Generation of the Driver File  The driver.py File  Flats  Wavelength Calibration \u2013 Y, J, and H Bands  Wavelength Calibration \u2013 K Band  Background Subtraction  Rectify  Spectral Extraction  Long2pos Reductions  Longslit Reductions  A Word About Header Comments  Some Hints   The manual is also available in pdf form:  MOSFIRE_DRP_Manual.pdf  \nNote: pdf version of the manual is generated from the individual markdown files for each section by running the  generate_pdf  script in the  docs/  subdirectory of this repository.",
            "title": "Table of Contents"
        },
        {
            "location": "/changes/",
            "text": "Change Log\n\n\nChanges in Version 2018\n\n\nNew features\n\n\n\n\nPython3 compatibility!\n\n\nImproved installation procedure uses anaconda cloud\n\n\nThe 1D spectral extraction code now provides the user the ability to set the default aperture width.\n\n\nRevamped documentation using mkdocs\n\n\n\n\nNote\n: This release of the DRP is only tested and supported on python 3.6+.  If you must use python 2, use the 2016 release of the DRP.  We encourage all users to use python 3 and we make the install of python 3 easy using anaconda python and the anaconda cloud (see the installation instructions).\n\n\nImprovements and bug fixes\n\n\n\n\nFixed bug where 1D extraction apertures could not be interactively positioned.\n\n\nFixed astropy deprecation warning related to clobber option\n\n\nFixed bug where slit nods with an odd number of positions would fail\n\n\nFixed numpy deprecation related to indexing arrays with non-integers\n\n\nFixed header info bug which would cause DS9 coordinates to display incorrectly\n\n\n\n\nChanges in Version 2016\n\n\nImportant Note\n: The \nUreka package has been deprecated\n as of April 26, 2016.  As a result, the MOSFIRE pipeline has migrated to a version which is not dependent on IRAF/PyRAF, but only on python packages.  It should work with any python install which provides the required packages and versions.\n\n\nNew features\n\n\n\n\nDRP is no longer dependent on IRAF/PyRAF\n\n\nThe use of IRAF's \ngeoxytran\n, \nimcombine\n, and \nimarith\n tasks have been replaced with python equivalents.\n\n\nThe DRP should now work with any python install which has the \nrequired python packages\n\n\n\n\n\n\nImproved slit tracing using a better thresholding algorithm\n\n\nAn updated (and now web based) \ninstruction manual\n\n\nThe DRP now performs optimal spectral extraction \nHorne 1986\n and outputs a 1D spectrum.  Please note that this is intended as a quick look tool, not for final science use.\n\n\nThe \nhandle\n step now writes \nfilelist.txt\n which contains a list of all the files processed by \nhandle\n instead of printing that output to the screen.  The file also contains messages for files not categorized for processing explaining why.  In addition, \nhandle\n now no longer writes list files with no content.  This is intended to make it easier to quickly see what files are available for reduction.\n\n\n\n\nImprovements and bug fixes\n\n\n\n\nChanged dependence on \npylab\n to \nmatplotlib.pyplot\n\n\nUses \nastropy.io.fits\n instead of \npyfits\n when available\n\n\nAdjust log messages to send more to DEBUG instead of INFO.  Leads to less clutter in messages visible to user.\n\n\n\n\nChanges in Version 2015A\n\n\nNew features\n\n\n\n\nReduction of long2pos and long2pos_specphot\n\n\nReduction of longslit data\n\n\nAutomatic generation of driver file\n\n\nLogging and diagnostic information on screen and on disk\n\n\nPackage-style installation as a Ureka sub-package\n\n\nSupport for Ureka 1.5.1\n\n\n\n\nImprovements and bug fixes\n\n\n\n\nFix incorrect determination of the slit parameters which prevented the use of large slits\n\n\nFix incorrect determination of the average wavelength dispersion for the long2pos mode\n\n\nAdded ability of specifying the output name of the files\n\n\nImproved robustness of non-interactive wavelength solution, added possibilty of switching from interactive to non-interactive during the reduction, added k-sigma clipping of the sky or arc lines\n\n\nFixed the problem with the interactive wavelength window not closing at the end of the fit\n\n\nFixed the problem with the interactive fitting window showing up empty on the first fit (no need to use the x key to unzoom)\n\n\nAdded procedure to fix the header of old images acquired with an outdated version of long2pos\n\n\nDisabled cosmic ray rejection for the case of less than 5 exposures\n\n\nThere is no need to specify one of the observations in Rectify: Rectify will use the first of the files listed in the Offset files.",
            "title": "Changes"
        },
        {
            "location": "/changes/#change-log",
            "text": "",
            "title": "Change Log"
        },
        {
            "location": "/changes/#changes-in-version-2018",
            "text": "",
            "title": "Changes in Version 2018"
        },
        {
            "location": "/changes/#new-features",
            "text": "Python3 compatibility!  Improved installation procedure uses anaconda cloud  The 1D spectral extraction code now provides the user the ability to set the default aperture width.  Revamped documentation using mkdocs   Note : This release of the DRP is only tested and supported on python 3.6+.  If you must use python 2, use the 2016 release of the DRP.  We encourage all users to use python 3 and we make the install of python 3 easy using anaconda python and the anaconda cloud (see the installation instructions).",
            "title": "New features"
        },
        {
            "location": "/changes/#improvements-and-bug-fixes",
            "text": "Fixed bug where 1D extraction apertures could not be interactively positioned.  Fixed astropy deprecation warning related to clobber option  Fixed bug where slit nods with an odd number of positions would fail  Fixed numpy deprecation related to indexing arrays with non-integers  Fixed header info bug which would cause DS9 coordinates to display incorrectly",
            "title": "Improvements and bug fixes"
        },
        {
            "location": "/changes/#changes-in-version-2016",
            "text": "Important Note : The  Ureka package has been deprecated  as of April 26, 2016.  As a result, the MOSFIRE pipeline has migrated to a version which is not dependent on IRAF/PyRAF, but only on python packages.  It should work with any python install which provides the required packages and versions.",
            "title": "Changes in Version 2016"
        },
        {
            "location": "/changes/#new-features_1",
            "text": "DRP is no longer dependent on IRAF/PyRAF  The use of IRAF's  geoxytran ,  imcombine , and  imarith  tasks have been replaced with python equivalents.  The DRP should now work with any python install which has the  required python packages    Improved slit tracing using a better thresholding algorithm  An updated (and now web based)  instruction manual  The DRP now performs optimal spectral extraction  Horne 1986  and outputs a 1D spectrum.  Please note that this is intended as a quick look tool, not for final science use.  The  handle  step now writes  filelist.txt  which contains a list of all the files processed by  handle  instead of printing that output to the screen.  The file also contains messages for files not categorized for processing explaining why.  In addition,  handle  now no longer writes list files with no content.  This is intended to make it easier to quickly see what files are available for reduction.",
            "title": "New features"
        },
        {
            "location": "/changes/#improvements-and-bug-fixes_1",
            "text": "Changed dependence on  pylab  to  matplotlib.pyplot  Uses  astropy.io.fits  instead of  pyfits  when available  Adjust log messages to send more to DEBUG instead of INFO.  Leads to less clutter in messages visible to user.",
            "title": "Improvements and bug fixes"
        },
        {
            "location": "/changes/#changes-in-version-2015a",
            "text": "",
            "title": "Changes in Version 2015A"
        },
        {
            "location": "/changes/#new-features_2",
            "text": "Reduction of long2pos and long2pos_specphot  Reduction of longslit data  Automatic generation of driver file  Logging and diagnostic information on screen and on disk  Package-style installation as a Ureka sub-package  Support for Ureka 1.5.1",
            "title": "New features"
        },
        {
            "location": "/changes/#improvements-and-bug-fixes_2",
            "text": "Fix incorrect determination of the slit parameters which prevented the use of large slits  Fix incorrect determination of the average wavelength dispersion for the long2pos mode  Added ability of specifying the output name of the files  Improved robustness of non-interactive wavelength solution, added possibilty of switching from interactive to non-interactive during the reduction, added k-sigma clipping of the sky or arc lines  Fixed the problem with the interactive wavelength window not closing at the end of the fit  Fixed the problem with the interactive fitting window showing up empty on the first fit (no need to use the x key to unzoom)  Added procedure to fix the header of old images acquired with an outdated version of long2pos  Disabled cosmic ray rejection for the case of less than 5 exposures  There is no need to specify one of the observations in Rectify: Rectify will use the first of the files listed in the Offset files.",
            "title": "Improvements and bug fixes"
        },
        {
            "location": "/preface/",
            "text": "Preface\n\n\nThis manual describes the installation and usage of the MOSFIRE data reduction pipeline on a unix-like computer. Although primarily tested and developed on a Mac, the pipeline operates on both OSX and Linux systems. In the section 4, we describe an installation procedure for a Mac OSX system. Later sections describe code usage, execution, and outputs.\n\n\nThe MOSFIRE spectrograph data reduction pipeline was architected by the MOSFIRE commissioning team and written by Nick Konidaris with extensive checking and feedback from Chuck Steidel and other MOSFIRE team members. The pipeline is maintained on an online code repository \nhttps://github.com/Keck-DataReductionPipelines/MosfireDRP\n. Please use this website to track issues and and submit requests.",
            "title": "Preface"
        },
        {
            "location": "/preface/#preface",
            "text": "This manual describes the installation and usage of the MOSFIRE data reduction pipeline on a unix-like computer. Although primarily tested and developed on a Mac, the pipeline operates on both OSX and Linux systems. In the section 4, we describe an installation procedure for a Mac OSX system. Later sections describe code usage, execution, and outputs.  The MOSFIRE spectrograph data reduction pipeline was architected by the MOSFIRE commissioning team and written by Nick Konidaris with extensive checking and feedback from Chuck Steidel and other MOSFIRE team members. The pipeline is maintained on an online code repository  https://github.com/Keck-DataReductionPipelines/MosfireDRP . Please use this website to track issues and and submit requests.",
            "title": "Preface"
        },
        {
            "location": "/installing/",
            "text": "Installation\n\n\nRequirements\n\n\nThe pipeline requires the following python modules:\n\n\n\n\nnumpy\n\n\nastropy\n\n\nccdproc\n\n\nscipy\n\n\n\n\nInstalling Python\n\n\nUsing Anaconda Cloud and Conda Environments\n\n\nInstall Anaconda as per the instructions on the \nAnaconda web site\n.\n\n\nNow we will create a conda \nenvironment\n specifically for the MOSFIRE DRP.  Rather than specify everything on the command line, we will get the specification for the environment from the Anaconda Cloud service.  There are two specifications, one for linux (tested on a CentOS 7 system) and one for macOS (tested on macOS 10.12.6).  Get the one appropriate for your system using one of the commands below:\n\n\nconda env create KeckObservatory/mospy_2018_linux\n\n\n\nor\n\n\nconda env create KeckObservatory/mospy_2018_macos\n\n\n\nNow we will invoke that environment:\n\n\nsource activate mospy_2018_linux\n\n\n\nor\n\n\nsource activate mospy_2018_macos\n\n\n\nNow we will install the DRP itself.  From now on, if you want to run the DRP, first invoke the appropriate environment using \nsource activate mospy_2018_linux\n or \nsource activate mospy_2018_macos\n.\n\n\nDownload and Install the DRP\n\n\nDownload the zip file of the released version from \nGitHub\n.\n\n\nMove the zip file to a location on your computer where you want the source code to reside, then unzip the file:\n\n\nunzip MosfireDRP-2018release.zip\n\n\n\nChange in to the resulting \nMosfireDRP-2018release/\n directory:\n\n\ncd MosfireDRP-2018release\n\n\n\nRun the install program:\n\n\npython setup.py install\n\n\n\nThe executable \nmospy\n should now be in your path.  If you used the Anaconda based install, it will be in the Anaconda bin directory (e.g. \n~/anaconda/envs/mospy_2018_macos/bin/mospy\n).\n\n\nAlternate Methods of Installing Python\n\n\nNote, these are no longer the recommended methods of installing the DRP as they do not gauranttee that the various package versions are compatible with the DRP.\n\n\nUsing the Anaconda Distribution\n\n\nInstall Anaconda as per the instructions on the \nAnaconda web site\n.  The pipeline currently (2016 release) only runs on python 2.7, so download and install that version, not the python 3.x version.\n\n\nTo generate an environment similar to the one in the recommended anaconda cloud based install, you can use the following command:\n\n\nconda create --no-default-packages -c astropy -n mospy_2018_macos python=3.6.3 astropy=2.0.3 ccdproc=1.3.0 ipython=6.2.1 numpy=1.13.3 scipy=1.0.0 PyQt=5.6.0\n\n\n\n\nYou should now have all the requirements to run the MOSFIRE DRP.  This should work on any anaconda install, even if the pre-packaged linux and macOS environments are incompatible with your machine.\n\n\nUsing Other Python Install Methods\n\n\nThe DRP support group recommends the anaconda python install and has tested the DRP using that installer, but if an appropriate version of python is installed via some other package manager (e.g. apt-get, brew, yum, etc.), then you should be able to install the python package dependencies using either that package manager (if they are available via that package manager) or using \npip\n.  For example:\n\n\npip install numpy\npip install astropy\npip install ccdproc",
            "title": "Installing"
        },
        {
            "location": "/installing/#installation",
            "text": "",
            "title": "Installation"
        },
        {
            "location": "/installing/#requirements",
            "text": "The pipeline requires the following python modules:   numpy  astropy  ccdproc  scipy",
            "title": "Requirements"
        },
        {
            "location": "/installing/#installing-python",
            "text": "",
            "title": "Installing Python"
        },
        {
            "location": "/installing/#using-anaconda-cloud-and-conda-environments",
            "text": "Install Anaconda as per the instructions on the  Anaconda web site .  Now we will create a conda  environment  specifically for the MOSFIRE DRP.  Rather than specify everything on the command line, we will get the specification for the environment from the Anaconda Cloud service.  There are two specifications, one for linux (tested on a CentOS 7 system) and one for macOS (tested on macOS 10.12.6).  Get the one appropriate for your system using one of the commands below:  conda env create KeckObservatory/mospy_2018_linux  or  conda env create KeckObservatory/mospy_2018_macos  Now we will invoke that environment:  source activate mospy_2018_linux  or  source activate mospy_2018_macos  Now we will install the DRP itself.  From now on, if you want to run the DRP, first invoke the appropriate environment using  source activate mospy_2018_linux  or  source activate mospy_2018_macos .",
            "title": "Using Anaconda Cloud and Conda Environments"
        },
        {
            "location": "/installing/#download-and-install-the-drp",
            "text": "Download the zip file of the released version from  GitHub .  Move the zip file to a location on your computer where you want the source code to reside, then unzip the file:  unzip MosfireDRP-2018release.zip  Change in to the resulting  MosfireDRP-2018release/  directory:  cd MosfireDRP-2018release  Run the install program:  python setup.py install  The executable  mospy  should now be in your path.  If you used the Anaconda based install, it will be in the Anaconda bin directory (e.g.  ~/anaconda/envs/mospy_2018_macos/bin/mospy ).",
            "title": "Download and Install the DRP"
        },
        {
            "location": "/installing/#alternate-methods-of-installing-python",
            "text": "Note, these are no longer the recommended methods of installing the DRP as they do not gauranttee that the various package versions are compatible with the DRP.",
            "title": "Alternate Methods of Installing Python"
        },
        {
            "location": "/installing/#using-the-anaconda-distribution",
            "text": "Install Anaconda as per the instructions on the  Anaconda web site .  The pipeline currently (2016 release) only runs on python 2.7, so download and install that version, not the python 3.x version.  To generate an environment similar to the one in the recommended anaconda cloud based install, you can use the following command:  conda create --no-default-packages -c astropy -n mospy_2018_macos python=3.6.3 astropy=2.0.3 ccdproc=1.3.0 ipython=6.2.1 numpy=1.13.3 scipy=1.0.0 PyQt=5.6.0  You should now have all the requirements to run the MOSFIRE DRP.  This should work on any anaconda install, even if the pre-packaged linux and macOS environments are incompatible with your machine.",
            "title": "Using the Anaconda Distribution"
        },
        {
            "location": "/installing/#using-other-python-install-methods",
            "text": "The DRP support group recommends the anaconda python install and has tested the DRP using that installer, but if an appropriate version of python is installed via some other package manager (e.g. apt-get, brew, yum, etc.), then you should be able to install the python package dependencies using either that package manager (if they are available via that package manager) or using  pip .  For example:  pip install numpy\npip install astropy\npip install ccdproc",
            "title": "Using Other Python Install Methods"
        },
        {
            "location": "/retrieve/",
            "text": "Retrieve\n\n\nBefore running the drp, you will need a set of spectroscopic data to reduce that includes flats, science observations, and if the observations are K-band, arcs and thermal flats. NOTE: You must preserve Keck\u2019s file naming convention as the DRP uses the file name to parse data sets. The standard naming convention is \nmYYMMDD_####.fits\n. \n\n\nIf you need to retrieve your data, you may either use a secure copy (scp) assumine your data is still accessible from the Keck/MOSFIRE data directory (contact your SA if you need assistance) or use KOA \u2013the Keck Observatory Archive to navigate to the KOA log in page. From there, KOA has forms where you specify the data to retrieve and will create a tar ball for you to download.\n\n\nA useful tool is the file translator script that will convert your KOA file names to the standard filenames as they were written to disk during your observing session (koa_translator). Again, your filenames must preserve the standard naming convention and the koa_translator script does this for you.\n\n\nIf you do not have data of your own and wish to download the example:\nGrab the data from: \nhttps://www2.keck.hawaii.edu/realpublic/inst/mosfire/DRP_Test_Case_Hband.zip\n.\n\n\nMove the test case zip file to a directory of your choice (we will assume \n~/Data\n for the examples in this manual) and unzip the DRP test case file:\n\n\nunzip DRP_Test_Case_Hband.zip\n\n\n\nThis will create a \nDRP_Test_Case_Hband\n subdirectory under your current directory which will contain the raw data which you can use to follow along in subsequent steps of the DRP manual.",
            "title": "Retrieve Your Data"
        },
        {
            "location": "/retrieve/#retrieve",
            "text": "Before running the drp, you will need a set of spectroscopic data to reduce that includes flats, science observations, and if the observations are K-band, arcs and thermal flats. NOTE: You must preserve Keck\u2019s file naming convention as the DRP uses the file name to parse data sets. The standard naming convention is  mYYMMDD_####.fits .   If you need to retrieve your data, you may either use a secure copy (scp) assumine your data is still accessible from the Keck/MOSFIRE data directory (contact your SA if you need assistance) or use KOA \u2013the Keck Observatory Archive to navigate to the KOA log in page. From there, KOA has forms where you specify the data to retrieve and will create a tar ball for you to download.  A useful tool is the file translator script that will convert your KOA file names to the standard filenames as they were written to disk during your observing session (koa_translator). Again, your filenames must preserve the standard naming convention and the koa_translator script does this for you.  If you do not have data of your own and wish to download the example:\nGrab the data from:  https://www2.keck.hawaii.edu/realpublic/inst/mosfire/DRP_Test_Case_Hband.zip .  Move the test case zip file to a directory of your choice (we will assume  ~/Data  for the examples in this manual) and unzip the DRP test case file:  unzip DRP_Test_Case_Hband.zip  This will create a  DRP_Test_Case_Hband  subdirectory under your current directory which will contain the raw data which you can use to follow along in subsequent steps of the DRP manual.",
            "title": "Retrieve"
        },
        {
            "location": "/handle/",
            "text": "Handle\n\n\nNow that you have data to reduce, we need to set up the pipeline with the appropriate files so that the drp knows what files to use in the reduction. The handle step will parses the FITS header information and determine what files are associated with each of your masks. \n\n\nBecause the DRP no longer has a designated output directory, you will need to run handle in your designated reduction sub-directory (\nreduced\n in our example).\n\n\nmkdir reduced\ncd reduced\nmospy handle /home/[yourhomedir]/Data/DRP_Test_Case_Hband/2012sep10/*fits\n\n\n\nPlease use the full path to the raw data when invoking \nmospy handle\n.\n\n\nA lot of data summarizing the observations is output. This includes a table of the observations:\n\n\nm130514_0132        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0133        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0134        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0135        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0136        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm140114_0137        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\n...\n\n\n\nand file lists that organize the observation types:\n\n\nmosmaskA /2013jan14/Y/Unknown.txt\nmosmaskA /2013jan14/Y/Align.txt\nmosmaskA /2013jan14/Y/MIRA.txt\nmosmaskA /2013jan14/Y/Ne.txt\nmosmaskA /2013jan14/Y/Offset_2.txt\nmosmaskA /2013jan14/Y/Offset_-2.txt\nmosmaskA /2013jan14/Y/Flat.txt\nmosmaskA /2013jan14/Y/Image.txt\nmosmaskA /2013jan14/Y/FlatThermal.txt\nmosmaskA /2013jan14/Y/Dark.txt\nmosmaskA /2013jan14/Y/Ar.txt\nmosmaskA 2013jan14/Y/Aborted.txt\n...\n\n\n\nThe handle step creates a set of directories organized as\n\n\n[maskname]/[date]/[band]/\n\n\n\nContaining\n\n\n\n\nAborted.txt: Aborted files\n\n\nAlign.txt: Alignment frames\n\n\nAr.txt: Argon spectra\n\n\nDark.txt: Darks \n\n\nFlat.txt: Flat fields\n\n\nFlatThermal.txt: Thermal Flats (lamps off)\n\n\nImage.txt: Imaging mode\n\n\nMIRA.txt: MIRA focus images\n\n\nNe.txt: Neon lamp spectra\n\n\nUnknown.txt: Unknown files\n\n\nOffset_[p].txt: Science frames\n\n\n\n\nThe output directory structure is designed to make finding reduced data easy, and to separate reductions of the same mask across multiple dates. Below is a screen shot showing the example output from an Offset*.txt file.\n\n\n\n\nFor longslit observations, separate offsets files are created for each object, but the same offset files are used if the same object is observed many times during the night. You might want to separate the different observations of the same object.\n\n\nFor long2pos observations, again different offset files are created for each object. Besides, the suffixes _PosA and _PosC are added to the offset files to identify the two left and right positions used in the observations.\n\n\nThe following section describes in details how to use the driver file to control the pipeline processes, and points at a number of standard driver files that we provide for reference.",
            "title": "Handle"
        },
        {
            "location": "/handle/#handle",
            "text": "Now that you have data to reduce, we need to set up the pipeline with the appropriate files so that the drp knows what files to use in the reduction. The handle step will parses the FITS header information and determine what files are associated with each of your masks.   Because the DRP no longer has a designated output directory, you will need to run handle in your designated reduction sub-directory ( reduced  in our example).  mkdir reduced\ncd reduced\nmospy handle /home/[yourhomedir]/Data/DRP_Test_Case_Hband/2012sep10/*fits  Please use the full path to the raw data when invoking  mospy handle .  A lot of data summarizing the observations is output. This includes a table of the observations:  m130514_0132        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0133        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0134        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0135        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm130114_0136        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\nm140114_0137        Flat:mos Y mosmaskA     16.0 s      mosmaskA   Y      YJ\n...  and file lists that organize the observation types:  mosmaskA /2013jan14/Y/Unknown.txt\nmosmaskA /2013jan14/Y/Align.txt\nmosmaskA /2013jan14/Y/MIRA.txt\nmosmaskA /2013jan14/Y/Ne.txt\nmosmaskA /2013jan14/Y/Offset_2.txt\nmosmaskA /2013jan14/Y/Offset_-2.txt\nmosmaskA /2013jan14/Y/Flat.txt\nmosmaskA /2013jan14/Y/Image.txt\nmosmaskA /2013jan14/Y/FlatThermal.txt\nmosmaskA /2013jan14/Y/Dark.txt\nmosmaskA /2013jan14/Y/Ar.txt\nmosmaskA 2013jan14/Y/Aborted.txt\n...  The handle step creates a set of directories organized as  [maskname]/[date]/[band]/  Containing   Aborted.txt: Aborted files  Align.txt: Alignment frames  Ar.txt: Argon spectra  Dark.txt: Darks   Flat.txt: Flat fields  FlatThermal.txt: Thermal Flats (lamps off)  Image.txt: Imaging mode  MIRA.txt: MIRA focus images  Ne.txt: Neon lamp spectra  Unknown.txt: Unknown files  Offset_[p].txt: Science frames   The output directory structure is designed to make finding reduced data easy, and to separate reductions of the same mask across multiple dates. Below is a screen shot showing the example output from an Offset*.txt file.   For longslit observations, separate offsets files are created for each object, but the same offset files are used if the same object is observed many times during the night. You might want to separate the different observations of the same object.  For long2pos observations, again different offset files are created for each object. Besides, the suffixes _PosA and _PosC are added to the offset files to identify the two left and right positions used in the observations.  The following section describes in details how to use the driver file to control the pipeline processes, and points at a number of standard driver files that we provide for reference.",
            "title": "Handle"
        },
        {
            "location": "/autodriver/",
            "text": "AutoDriver\n\n\nThe pipeline is able to produce a driver file automatically for most cases, thus removing the need to copy one of the standard files and manually edit it.\n\n\nTo generate the driver file, go to the directory where your Offset files live, and where the reduction is going to happen and type:\n\n\nmospy AutoDriver\n\n\n\nThis will generate a file called Driver.py, which you should inspect before running it. Highly specialized cases such as particular combinations of sky lines and arcs might not be dealt with correctly. Note that the automatic generation of the driver file works for long2pos and longslit as well.\n\n\nTo handle special cases, the automatic generation of the driver file makes a number of assumptions, that might not be correct for your science case.\n\n\n\n\nIf either Ar.txt or Ne.txt or both are available, they are being used.\n\n\nIf the band is K, and FlatThermal.txtis available, it is used\n\n\nFor long2pos: if no arcs are available, only specphot in non spectrophotometric mode can be reduced and the pipeline will attempt to use the sky lines. Note that is likely to fail, as sky lines are too faint in short exposures for an accurate wavelength determination. The spectrophotometric mode contains wide slits that cannot be reduced using sky lines only.\n\n\nIn longslit, the pipeline will try to determine the size of the slit using the mask name. For example, if the maskname is LONGSLIT-3x0.7, the pipeline assumes that you have used 3 slits to generate the longslit and that they are centered around the middle line of the detector.\n\n\nIf any of the mandatory observations are missing (such as the flat fields), the pipeline will still generate a Driver.py file, but it will contain warnings about the missing files, and it will NOT run correctly.\n\n\nIf multiple observations of different stars are done in long2pos or in longslit mode, the pipeline will generate multiple driver files, one for each object. If the same object is observed multiple times during the same night, all the observations will end up in the same driver file. If you are observing a telluric standard at different times and you need to have separate spectra, you need to manually create Offset files and Driver files.",
            "title": "Automatic Generation of the Driver File"
        },
        {
            "location": "/autodriver/#autodriver",
            "text": "The pipeline is able to produce a driver file automatically for most cases, thus removing the need to copy one of the standard files and manually edit it.  To generate the driver file, go to the directory where your Offset files live, and where the reduction is going to happen and type:  mospy AutoDriver  This will generate a file called Driver.py, which you should inspect before running it. Highly specialized cases such as particular combinations of sky lines and arcs might not be dealt with correctly. Note that the automatic generation of the driver file works for long2pos and longslit as well.  To handle special cases, the automatic generation of the driver file makes a number of assumptions, that might not be correct for your science case.   If either Ar.txt or Ne.txt or both are available, they are being used.  If the band is K, and FlatThermal.txtis available, it is used  For long2pos: if no arcs are available, only specphot in non spectrophotometric mode can be reduced and the pipeline will attempt to use the sky lines. Note that is likely to fail, as sky lines are too faint in short exposures for an accurate wavelength determination. The spectrophotometric mode contains wide slits that cannot be reduced using sky lines only.  In longslit, the pipeline will try to determine the size of the slit using the mask name. For example, if the maskname is LONGSLIT-3x0.7, the pipeline assumes that you have used 3 slits to generate the longslit and that they are centered around the middle line of the detector.  If any of the mandatory observations are missing (such as the flat fields), the pipeline will still generate a Driver.py file, but it will contain warnings about the missing files, and it will NOT run correctly.  If multiple observations of different stars are done in long2pos or in longslit mode, the pipeline will generate multiple driver files, one for each object. If the same object is observed multiple times during the same night, all the observations will end up in the same driver file. If you are observing a telluric standard at different times and you need to have separate spectra, you need to manually create Offset files and Driver files.",
            "title": "AutoDriver"
        },
        {
            "location": "/driver/",
            "text": "The driver.py File\n\n\nThe driver file controls all the pipeline steps, and in the drivers sub-directory, you will find a number of driver files: \nDriver.py\n, \nK_Driver.py\n, \nLong2pos_driver.py\n, and \nLongslit_Driver.py\n. The \nDriver\n and \nK_Driver\n will reduce your science data for bands Y,J, and H (this includes the sample data set). The K band requires a special approach because there are too few bright night-sky emission lines at the red end and so the \nK_Driver\n synthesizes arclamps and night sky lines. The \nLong2pos_driver.py\n handles \nlong2pos\n and \nlong2pos_specphot\n observations, while the \nLongslit_driver.py\n deals with observations of single objects using a longslit configuration.\n\n\nThe driver.py files included with the code download contains execution lines that are commented out. For this example, we will run the driver file one line at a time, but as you become familiar with the DRP process, you will develop your own driver file execution sequencing. Although in the future we hope to further automate the driver file, currently some steps require you to update the inputs with filenames created from previous steps. \n\n\nBelow is a driver.py file:\n\n\nimport os, time\nimport MOSFIRE\n\nfrom MOSFIRE import Background, Combine, Detector, Flats, IO, Options, \\\n     Rectify\nfrom MOSFIRE import Wavelength\n\nimport numpy as np, pylab as pl, pyfits as pf\n\nnp.seterr(all=\"ignore\")\n\n#Update the insertmaskname with the name of the mask\n#Update S with the filter band Y,J,H,or K\nmaskname = 'insertmaskname'\nband = 'S'\n\nflatops = Options.flat\nwaveops = Options.wavelength\n\nobsfiles = ['Offset_1.5.txt', 'Offset_-1.5.txt']\n\n#Flats.handle_flats('Flat.txt', maskname, band, flatops)\n#Wavelength.imcombine(obsfiles, maskname, band, waveops)\n#Wavelength.fit_lambda_interactively(maskname, band, obsfiles,\n    #waveops)\n#Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles,\n    #waveops)\n\n#Wavelength.apply_lambda_simple(maskname, band, obsfiles, waveops)\n#Background.handle_background(obsfiles,\n    #'lambda_solution_wave_stack_H_m130429_0224-0249.fits',\n    #maskname, band, waveops)\n\nredfiles = [\"eps_\" + file + \".fits\" for file in obsfiles]\n#Rectify.handle_rectification(maskname, redfiles,\n#    \"lambda_solution_wave_stack_H_m130429_0224-0249.fits\",\n#    band, \n#    \"/scr2/npk/mosfire/2013apr29/m130429_0224.fits\",\n#    waveops)\n#\n\n\n\nTo set up your driver file do the following:\n\n\n\n\nNavigate to the desired output directory created by handle: \ncd ~/Data/reducedMOSFIRE_DRP_MASK/2012sep10/H\n\n\nCopy the appropriate driver file: \ncp ~/MosfireDRP-master/drivers/Driver.py .\n  NOTE: If you are observing a K band mask you\u2019ll want to copy the \nK_driver.py\n file over.\n\n\nEdit driver.py (see bold text in driver file example)\n\n\nUpdate maskname\n\n\nUpdate band to be Y,J,H\n\n\nUpdate the \nOffset_#.txt\n name. Handle creates offset files with names that are specific to the nod throw. The default driver file uses 1.5 arcsec offsets in the file name. \n\n\n\n\n\n\n\n\nIn the sections that follow, we will describe the function and outputs of the commented lines found in the driver file starting with the creation of flats.\n\n\nIf you prefer to override the standard naming convention of the output files, you can specify\n\n\ntarget = \u201ctargetname\u201d\n\n\n\nat the beginning of the driver file. If you do so, remember to also add target=target to both the Background and Rectify steps. Example:\n\n\nBackground.handle_background(obsfiles,\n    'lambda_solution_wave_stack_H_m150428_0091-0091.fits',\n    maskname, band, waveops, target=target)",
            "title": "The driver.py File"
        },
        {
            "location": "/driver/#the-driverpy-file",
            "text": "The driver file controls all the pipeline steps, and in the drivers sub-directory, you will find a number of driver files:  Driver.py ,  K_Driver.py ,  Long2pos_driver.py , and  Longslit_Driver.py . The  Driver  and  K_Driver  will reduce your science data for bands Y,J, and H (this includes the sample data set). The K band requires a special approach because there are too few bright night-sky emission lines at the red end and so the  K_Driver  synthesizes arclamps and night sky lines. The  Long2pos_driver.py  handles  long2pos  and  long2pos_specphot  observations, while the  Longslit_driver.py  deals with observations of single objects using a longslit configuration.  The driver.py files included with the code download contains execution lines that are commented out. For this example, we will run the driver file one line at a time, but as you become familiar with the DRP process, you will develop your own driver file execution sequencing. Although in the future we hope to further automate the driver file, currently some steps require you to update the inputs with filenames created from previous steps.   Below is a driver.py file:  import os, time\nimport MOSFIRE\n\nfrom MOSFIRE import Background, Combine, Detector, Flats, IO, Options, \\\n     Rectify\nfrom MOSFIRE import Wavelength\n\nimport numpy as np, pylab as pl, pyfits as pf\n\nnp.seterr(all=\"ignore\")\n\n#Update the insertmaskname with the name of the mask\n#Update S with the filter band Y,J,H,or K\nmaskname = 'insertmaskname'\nband = 'S'\n\nflatops = Options.flat\nwaveops = Options.wavelength\n\nobsfiles = ['Offset_1.5.txt', 'Offset_-1.5.txt']\n\n#Flats.handle_flats('Flat.txt', maskname, band, flatops)\n#Wavelength.imcombine(obsfiles, maskname, band, waveops)\n#Wavelength.fit_lambda_interactively(maskname, band, obsfiles,\n    #waveops)\n#Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles,\n    #waveops)\n\n#Wavelength.apply_lambda_simple(maskname, band, obsfiles, waveops)\n#Background.handle_background(obsfiles,\n    #'lambda_solution_wave_stack_H_m130429_0224-0249.fits',\n    #maskname, band, waveops)\n\nredfiles = [\"eps_\" + file + \".fits\" for file in obsfiles]\n#Rectify.handle_rectification(maskname, redfiles,\n#    \"lambda_solution_wave_stack_H_m130429_0224-0249.fits\",\n#    band, \n#    \"/scr2/npk/mosfire/2013apr29/m130429_0224.fits\",\n#    waveops)\n#  To set up your driver file do the following:   Navigate to the desired output directory created by handle:  cd ~/Data/reducedMOSFIRE_DRP_MASK/2012sep10/H  Copy the appropriate driver file:  cp ~/MosfireDRP-master/drivers/Driver.py .   NOTE: If you are observing a K band mask you\u2019ll want to copy the  K_driver.py  file over.  Edit driver.py (see bold text in driver file example)  Update maskname  Update band to be Y,J,H  Update the  Offset_#.txt  name. Handle creates offset files with names that are specific to the nod throw. The default driver file uses 1.5 arcsec offsets in the file name.      In the sections that follow, we will describe the function and outputs of the commented lines found in the driver file starting with the creation of flats.  If you prefer to override the standard naming convention of the output files, you can specify  target = \u201ctargetname\u201d  at the beginning of the driver file. If you do so, remember to also add target=target to both the Background and Rectify steps. Example:  Background.handle_background(obsfiles,\n    'lambda_solution_wave_stack_H_m150428_0091-0091.fits',\n    maskname, band, waveops, target=target)",
            "title": "The driver.py File"
        },
        {
            "location": "/flats/",
            "text": "Flats\n\n\nThe first action the driver file will take is to generate a pixel flat and slit edge tracing. To initiate the flat generation, uncomment the line below in the \nDriver.py file: \n\n\n#Flats.handle_flats('Flat.txt', maskname, band, flatops)\n\n\n\nand in your xterm run the DRP \n\n\n> mospy Driver.py\n\n\n\nExample output from the xterm session\n\n\n> mospy Driver.py\n... Truncated output ...\nFlat written to combflat_2d_H.fits\n\n00] Finding Slit Edges for BX113 ending at 1901. Slit composed of 3 CSU slits\n01] Finding Slit Edges for BX129 ending at 1812. Slit composed of 2 CSU slits\n02] Finding Slit Edges for xS15 ending at 1768. Slit composed of 1 CSU slits\nSkipping (wavelength pixel): 10\n03] Finding Slit Edges for BX131 ending at 1680. Slit composed of 2 CSU slits\n\n\n\nThe slit names output to the screen should look familiar as they originated from the mask design process. The output files from this process are the following:\n\n\n\n\n\n\n\n\nFilename\n\n\nContains\n\n\n\n\n\n\n\n\n\n\ncombflat_2d_J.fits\n\n\nFITS image of the flats\n\n\n\n\n\n\nflatcombine.lst\n\n\nThe list of files used in the creation of the flat. Contains the full path name to the files.\n\n\n\n\n\n\npixelflat_2d_J.fits\n\n\nFITS image of the normalized flat. This is the flat used in other redution steps.\n\n\n\n\n\n\nslit-edges_J.npy\n\n\nFile containing the slit edge information\n\n\n\n\n\n\nslit-edges_J.reg\n\n\nDS9 regions file that may be overlayed to show the locations of the slits.\n\n\n\n\n\n\n\n\nAt the end, check the output in ds9. For example:\n\n\n> ds9 pixelflat_2d_H.fits -region slit-edges_H.reg\n\n\n\nThe regions file overlayed on the pixelflat image should look something like:\n\n\n\n\nThe green lines must trace the edge of the slit. If they don\u2019t, then the flat step failed. All values should be around 1.0. There are some big features in the detector that you will become familiar with over time.\n\n\nK-band flats\n\n\nAt K-band, the dome is hot enough that light is detected at the longest wavelengths at a level of a few hundred counts. Little to no light is seen at the shortest wavelengths. The light from the dome is not entering MOSFIRE at the same angles that the light from the spot illuminated on the dome by the dome lights. Some observers may wish to correct for this difference by subtracting the thermal flat emission from the dome flat emission before normalizing the flats. To complete this flat subtraction, you use the optional keyword lampsofflist in the flat process as seen in the command below:\n\n\nFlats.handle_flats('Flat.txt', maskname, band, flatops, lampOffList='FlatThermal.txt')\n\n\n\nIf thermal flats were included in your calibration sequence (default behavior for K-band), then the FlatThermal.txt file should be populated with a list of thermal flats. Use FlatThermal.txt as the list or modify it as you see necessary.\n\n\nThe outputs from the flat process will include two additional files. \n\n\n\n\ncombflat_lamps_off_2d_K.fits\n\n\ncombflat_lamps_on_2d_K.fits\n\n\n\n\nand now the combflat_2d_K.fits being the difference between the two files.",
            "title": "Flats"
        },
        {
            "location": "/flats/#flats",
            "text": "The first action the driver file will take is to generate a pixel flat and slit edge tracing. To initiate the flat generation, uncomment the line below in the \nDriver.py file:   #Flats.handle_flats('Flat.txt', maskname, band, flatops)  and in your xterm run the DRP   > mospy Driver.py  Example output from the xterm session  > mospy Driver.py\n... Truncated output ...\nFlat written to combflat_2d_H.fits\n\n00] Finding Slit Edges for BX113 ending at 1901. Slit composed of 3 CSU slits\n01] Finding Slit Edges for BX129 ending at 1812. Slit composed of 2 CSU slits\n02] Finding Slit Edges for xS15 ending at 1768. Slit composed of 1 CSU slits\nSkipping (wavelength pixel): 10\n03] Finding Slit Edges for BX131 ending at 1680. Slit composed of 2 CSU slits  The slit names output to the screen should look familiar as they originated from the mask design process. The output files from this process are the following:     Filename  Contains      combflat_2d_J.fits  FITS image of the flats    flatcombine.lst  The list of files used in the creation of the flat. Contains the full path name to the files.    pixelflat_2d_J.fits  FITS image of the normalized flat. This is the flat used in other redution steps.    slit-edges_J.npy  File containing the slit edge information    slit-edges_J.reg  DS9 regions file that may be overlayed to show the locations of the slits.     At the end, check the output in ds9. For example:  > ds9 pixelflat_2d_H.fits -region slit-edges_H.reg  The regions file overlayed on the pixelflat image should look something like:   The green lines must trace the edge of the slit. If they don\u2019t, then the flat step failed. All values should be around 1.0. There are some big features in the detector that you will become familiar with over time.",
            "title": "Flats"
        },
        {
            "location": "/flats/#k-band-flats",
            "text": "At K-band, the dome is hot enough that light is detected at the longest wavelengths at a level of a few hundred counts. Little to no light is seen at the shortest wavelengths. The light from the dome is not entering MOSFIRE at the same angles that the light from the spot illuminated on the dome by the dome lights. Some observers may wish to correct for this difference by subtracting the thermal flat emission from the dome flat emission before normalizing the flats. To complete this flat subtraction, you use the optional keyword lampsofflist in the flat process as seen in the command below:  Flats.handle_flats('Flat.txt', maskname, band, flatops, lampOffList='FlatThermal.txt')  If thermal flats were included in your calibration sequence (default behavior for K-band), then the FlatThermal.txt file should be populated with a list of thermal flats. Use FlatThermal.txt as the list or modify it as you see necessary.  The outputs from the flat process will include two additional files.    combflat_lamps_off_2d_K.fits  combflat_lamps_on_2d_K.fits   and now the combflat_2d_K.fits being the difference between the two files.",
            "title": "K-band flats"
        },
        {
            "location": "/wavelengthYJH/",
            "text": "Wavelength Calibration (Y, J, H)\n\n\nIn the shorter wavebands, when using the recommended exposure times, the wavelength calibration is performed on night sky lines. The mospy Wavelength module is responsbile for these operations. See the example driver file in section 7.\n\n\nCombine files\n\n\nFirst step is to produce a file with which you will train your wavelength solution. Since we\u2019re using night sky lines for training, the approach is to combine individual science exposures. This is performed by the python Wavelength.imcombine routine. For a lot of users, this will look something like in the Driver.py file:\n\n\nWavelength.imcombine(obsfiles, maskname, band, waveops)\n\n\n\nThe first parameter is obsfiles which is a python string array indicating the list of files in the offset positions. Note that obsfiles has defaults of \u201cOffset_1.5.txt\u201d and \u201cOffset_-1.5.txt\u201d and may need to be updated as described in section 6. \n\n\nSuppose you want to exclude a file for reasons such as weather or telescope fault, simply remove the offending file from the appropriate Offset_*.txt. Likewise, you are welcome to add files in as you like, such as observations from the previous night.\n\n\nOutputs of this step are:\n\n\n\n\n\n\n\n\nFilename\n\n\nContains\n\n\n\n\n\n\n\n\n\n\nwave_stack_[band]_[range].fits\n\n\nA median-combined image of the files to be used for the wavelength solution.\n\n\n\n\n\n\n\n\nInteractive wavelength fitting\n\n\nThe next step is to use the wave_stack_*.fits file and determine an initial wavelength solution for each slit. During this process, we interactively fit the lines using a gui that displays. To initiate this process, uncomment the line in the Driver.py file:\n\n\n#Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles, waveops)\n\n\n\nAnd then re-execute the driver file: \n\n\nmospy Driver.py\n\n\n\nwhen you run this step, a GUI window appears.\n\n\n\n\nThe interactive wavelength solving window. This is a J-band night sky spectrum.\n\n\n\n\nThe interactive wavelength solving window showing an initial fit. This is a J-band night sky spectrum and one of the night sky lines on the right hand side is clearly a poor fit compared to the rest of the identified lines.\n\n\n\n\nThe interactive wavelength solving window showing a good fit with the initial poor line removed from the calculation. \nThe interactive wavelength solving window showing an initial fit. This is a J-band night sky spectrum and one of the night sky lines on the right hand side is clearly a poor fit compared to the rest of the identified lines.\n\n\nPlotted in the gui will be a sky line spectrum and vertical lines denoting positions and wavelengths of the sky lines. Your goal is to help the pipeline by identifying the night sky lines in the center of each slit. Once you come up with a good solution in the center, the pipeline will propagate it spatially along the slit. In the gui, Press ? to see a list of commands in the console window. The list of commands available on the GUI are:\n\n\n\n\nc - to center on the nearest peak (first thing to do to shift the initial wavelength guess) \n\n\nc - Center the nearest line at the cursor position \n\n\n\\ - Fit fit the data\n\n\nf \u2013 Alternate way to fit the data, equivalent to \\ but may cause the spectrum to become full screen.\n\n\nk \u2013 Toggles k-sigma clipping on and off. Also performs a new fit.\n\n\nb -  Turns on bypass mode. From now on, the interactive window is not displayed and the fit continues automatically.\n\n\nd - Delete a point (remove the wackadoos) \n\n\nn - proceed to the Next object \n\n\np - return to back to the Previous object \n\n\nr - Reset the current slit (try this if the plot looks strange) \n\n\nz - Zoom at cursor position \n\n\nx - Unzoom: full screen \n\n\ns - Save figure to disk \n\n\nh - Help \n\n\nq - Quit and save results \n\n\n\n\nBelow is a rough procedure for completing the interactive fitting process. The steps you need to take are as follows. \n\n\n\n\nFirst, check to see if the orange lines match up with obvious night sky lines. If not the expected position does not match the actually position of the line do the following:\n\n\nPlace your cursor over a line\n\n\nPress the \u201cc\u2019 button that will shift the predicted position to the observed line. \n\n\n\n\n\n\nPress \u201cf\u201d to fit. An initial fit is done automatically (starting with version 2015A) A Chebyshev polynomial, f, such that f(pixel #) returns the wavelength in Angstroms.\n\n\nYou can chose to use k-sigma clipping to avoid the manual operation of removing bad lines with the \u201ck\u201d key. \n\n\nPress \"x\" to unzoom to the full size region\n\n\nAssess the fit:\n\n\nIf a line is poorly fit and should be removed\n\n\nMove the cursor to the line\n\n\nPress \u201cd\u201d to delete the line from the fit\n\n\n\n\n\n\nFor good fits, the residual points turn green.\n\n\n\n\n\n\nWhen the satisfied with the fit, press \u201cn\u201d to move to the next object.\n\n\nIf you want to disable the interactive fit and switch to the automatic fit, press \u201cb\u201d (bypass)\n\n\nRepeat the process above until you see the red Done! text in the center of your screen. \n\n\nPress \u201cq\u201d to quit the interactive gui and move to the next step.\n\n\n\n\nThe prompt should return following the fitting process. The outputs from this process are:\n\n\n\n\n\n\n\n\nFilename\n\n\nContains\n\n\n\n\n\n\n\n\n\n\nbarset.npy\n\n\nbar positions for each slit are specified\n\n\n\n\n\n\nlambda_center_coeffs_wave_stack_band_filenames.npy\n\n\nThe coefficients of the fit and positions of the measured lines.\n\n\n\n\n\n\n\n\nWavelength fitting for the entire slit\n\n\nThe next step in the wavelength fitting process is to propogate the solution spatially along each slit. To complete this process we uncomment the line in the Driver.py file:  \n\n\n#Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles, waveops)\n\n\n\nThis is one of the longer running processes and the output should look something like:\n\n\n...\nresid ang S09 @ p 978: 0.10 rms 0.07 mad [shift-22]\nresid ang S09 @ p 979: 0.09 rms 0.06 mad [shift-22]\nresid ang S09 @ p 980: 0.10 rms 0.06 mad [shift-22]\nresid ang S09 @ p 981: 0.09 rms 0.06 mad [shift-22]\nresid ang S09 @ p 982: 0.08 rms 0.05 mad [shift-22]\nresid ang S09 @ p 983: 0.08 rms 0.04 mad [shift-22]\n...\n\n\n\nThe prompt should return following the fitting process. The outputs from this process are:\n\n\n\n\n\n\n\n\nFilename\n\n\nContains\n\n\n\n\n\n\n\n\n\n\nlambda_coeffs_wave_stack_J_m130114_0443-0445.npy\n\n\ncoefficients of the fit for each row within the slit\n\n\n\n\n\n\n\n\nApply the wavelength solution\n\n\nThe last step in the wavelength fitting process is to apply the solution and create maps of the wavelength for the data set. To complete this process we uncomment the line in the Driver.py file:  \n\n\n  #Wavelength.apply_lambda_simple(maskname, band, obsfiles, waveops)\n\n\n\nThe prompt should return following the fitting process. The outputs from this process are:\n\n\n\n\n\n\n\n\nFilename\n\n\nContains\n\n\n\n\n\n\n\n\n\n\nlambda_solution_wave_stack_J_m130114_0443-0445.fits\n\n\ncontains a map of the wavelength for each pixel in the spectra\n\n\n\n\n\n\nsigs_solution_wave_stack_J_m130114_0443-0445.fits\n\n\ncontains the uncertainty in the measured wavelength position for each pixel in the spectra\n\n\n\n\n\n\nrectified_wave_stack_J_m130114_0443-0445.fits\n\n\ncontains the spatially and wavelength rectified resampled sky emission. A column in the image contains all pixels at the same wavelength.",
            "title": "Wavelength Calibration \u2013 Y, J, and H Bands"
        },
        {
            "location": "/wavelengthYJH/#wavelength-calibration-y-j-h",
            "text": "In the shorter wavebands, when using the recommended exposure times, the wavelength calibration is performed on night sky lines. The mospy Wavelength module is responsbile for these operations. See the example driver file in section 7.",
            "title": "Wavelength Calibration (Y, J, H)"
        },
        {
            "location": "/wavelengthYJH/#combine-files",
            "text": "First step is to produce a file with which you will train your wavelength solution. Since we\u2019re using night sky lines for training, the approach is to combine individual science exposures. This is performed by the python Wavelength.imcombine routine. For a lot of users, this will look something like in the Driver.py file:  Wavelength.imcombine(obsfiles, maskname, band, waveops)  The first parameter is obsfiles which is a python string array indicating the list of files in the offset positions. Note that obsfiles has defaults of \u201cOffset_1.5.txt\u201d and \u201cOffset_-1.5.txt\u201d and may need to be updated as described in section 6.   Suppose you want to exclude a file for reasons such as weather or telescope fault, simply remove the offending file from the appropriate Offset_*.txt. Likewise, you are welcome to add files in as you like, such as observations from the previous night.  Outputs of this step are:     Filename  Contains      wave_stack_[band]_[range].fits  A median-combined image of the files to be used for the wavelength solution.",
            "title": "Combine files"
        },
        {
            "location": "/wavelengthYJH/#interactive-wavelength-fitting",
            "text": "The next step is to use the wave_stack_*.fits file and determine an initial wavelength solution for each slit. During this process, we interactively fit the lines using a gui that displays. To initiate this process, uncomment the line in the Driver.py file:  #Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles, waveops)  And then re-execute the driver file:   mospy Driver.py  when you run this step, a GUI window appears.   The interactive wavelength solving window. This is a J-band night sky spectrum.   The interactive wavelength solving window showing an initial fit. This is a J-band night sky spectrum and one of the night sky lines on the right hand side is clearly a poor fit compared to the rest of the identified lines.   The interactive wavelength solving window showing a good fit with the initial poor line removed from the calculation. \nThe interactive wavelength solving window showing an initial fit. This is a J-band night sky spectrum and one of the night sky lines on the right hand side is clearly a poor fit compared to the rest of the identified lines.  Plotted in the gui will be a sky line spectrum and vertical lines denoting positions and wavelengths of the sky lines. Your goal is to help the pipeline by identifying the night sky lines in the center of each slit. Once you come up with a good solution in the center, the pipeline will propagate it spatially along the slit. In the gui, Press ? to see a list of commands in the console window. The list of commands available on the GUI are:   c - to center on the nearest peak (first thing to do to shift the initial wavelength guess)   c - Center the nearest line at the cursor position   \\ - Fit fit the data  f \u2013 Alternate way to fit the data, equivalent to \\ but may cause the spectrum to become full screen.  k \u2013 Toggles k-sigma clipping on and off. Also performs a new fit.  b -  Turns on bypass mode. From now on, the interactive window is not displayed and the fit continues automatically.  d - Delete a point (remove the wackadoos)   n - proceed to the Next object   p - return to back to the Previous object   r - Reset the current slit (try this if the plot looks strange)   z - Zoom at cursor position   x - Unzoom: full screen   s - Save figure to disk   h - Help   q - Quit and save results    Below is a rough procedure for completing the interactive fitting process. The steps you need to take are as follows.    First, check to see if the orange lines match up with obvious night sky lines. If not the expected position does not match the actually position of the line do the following:  Place your cursor over a line  Press the \u201cc\u2019 button that will shift the predicted position to the observed line.     Press \u201cf\u201d to fit. An initial fit is done automatically (starting with version 2015A) A Chebyshev polynomial, f, such that f(pixel #) returns the wavelength in Angstroms.  You can chose to use k-sigma clipping to avoid the manual operation of removing bad lines with the \u201ck\u201d key.   Press \"x\" to unzoom to the full size region  Assess the fit:  If a line is poorly fit and should be removed  Move the cursor to the line  Press \u201cd\u201d to delete the line from the fit    For good fits, the residual points turn green.    When the satisfied with the fit, press \u201cn\u201d to move to the next object.  If you want to disable the interactive fit and switch to the automatic fit, press \u201cb\u201d (bypass)  Repeat the process above until you see the red Done! text in the center of your screen.   Press \u201cq\u201d to quit the interactive gui and move to the next step.   The prompt should return following the fitting process. The outputs from this process are:     Filename  Contains      barset.npy  bar positions for each slit are specified    lambda_center_coeffs_wave_stack_band_filenames.npy  The coefficients of the fit and positions of the measured lines.",
            "title": "Interactive wavelength fitting"
        },
        {
            "location": "/wavelengthYJH/#wavelength-fitting-for-the-entire-slit",
            "text": "The next step in the wavelength fitting process is to propogate the solution spatially along each slit. To complete this process we uncomment the line in the Driver.py file:    #Wavelength.fit_lambda(maskname, band, obsfiles, obsfiles, waveops)  This is one of the longer running processes and the output should look something like:  ...\nresid ang S09 @ p 978: 0.10 rms 0.07 mad [shift-22]\nresid ang S09 @ p 979: 0.09 rms 0.06 mad [shift-22]\nresid ang S09 @ p 980: 0.10 rms 0.06 mad [shift-22]\nresid ang S09 @ p 981: 0.09 rms 0.06 mad [shift-22]\nresid ang S09 @ p 982: 0.08 rms 0.05 mad [shift-22]\nresid ang S09 @ p 983: 0.08 rms 0.04 mad [shift-22]\n...  The prompt should return following the fitting process. The outputs from this process are:     Filename  Contains      lambda_coeffs_wave_stack_J_m130114_0443-0445.npy  coefficients of the fit for each row within the slit",
            "title": "Wavelength fitting for the entire slit"
        },
        {
            "location": "/wavelengthYJH/#apply-the-wavelength-solution",
            "text": "The last step in the wavelength fitting process is to apply the solution and create maps of the wavelength for the data set. To complete this process we uncomment the line in the Driver.py file:      #Wavelength.apply_lambda_simple(maskname, band, obsfiles, waveops)  The prompt should return following the fitting process. The outputs from this process are:     Filename  Contains      lambda_solution_wave_stack_J_m130114_0443-0445.fits  contains a map of the wavelength for each pixel in the spectra    sigs_solution_wave_stack_J_m130114_0443-0445.fits  contains the uncertainty in the measured wavelength position for each pixel in the spectra    rectified_wave_stack_J_m130114_0443-0445.fits  contains the spatially and wavelength rectified resampled sky emission. A column in the image contains all pixels at the same wavelength.",
            "title": "Apply the wavelength solution"
        },
        {
            "location": "/wavelengthK/",
            "text": "Wavelength Calibration (K)\n\n\nThe night sky lines at the red end of the K-band are too faint to achieve small-fraction of a pixel RMS wavelength calibration. You will have to observe a Neon and Argon arc lamps during your afternoon calibrations. By default, the calibration script at the observatory is setup to acquire both the Ne and Argon arcs.\n\n\nBecause the beams emminating from the arclamp do not follow the same path as the beams coming from the sky, there will be a slight difference between the two solutions. For the afformentioned beam matching reason, the most accurate solution is the night sky lines. Thus, the code has to be clever about merging the two solutions.\n\n\nThe following subsections describe the additional steps that are necessary to process the arcline data and combine the arcs and night sky line wavelength solutions.\n\n\nCombine the arc line spectra\n\n\nJust like the step in section 8.1 where you combined the science frames to create nightsky line spectra, we first need to combine the arcline data. The arcs are typically three files and you should see them listed in the Ne.txt and Ar.txt file lists in your K band sub directory. To combine the images simply uncomment and run:\n\n\nWavelength.imcombine('Ne.txt', maskname, band, waveops)                                                                                                    \nWavelength.imcombine('Ar.txt', maskname, band, waveops)\n\n\n\nIdentify arc lines using night sky solution\n\n\nInstead of having to interactively determine the wavelenth solution for the arcs like we did in section 8.2 for the night sky lines, we are going to use the solutions for the night sky lines as a first approximation for the arcs. This may usually be done because the arcs differ from the night sky lines by a fractions of pixels. You are welcome to interactively solve the neon lamp solution with the Wavelength.fit_lambda_interactively routine; however, the need to run the interactive solution method should be rare. \n\n\nTo apply the solution from the night sky lines to the arcs center slit position, uncomment and run the following lines.\n\n\nWavelength.apply_interactive(maskname, band, waveops, apply=obsfiles, to='Ne.txt', neon=True)                                                              \nWavelength.apply_interactive(maskname, band, waveops, apply=obsfiles, to='Ar.txt', argon=True)\n\n\n\nThis step, when run will produce output like:\n\n\nslitno  1 STD: 0.16 MAD: 0.06\nslitno  2 STD: 0.03 MAD: 0.02\nslitno  3 STD: 0.04 MAD: 0.04\nslitno  4 STD: 0.05 MAD: 0.01\n\n\n\nFor each slit, a new solution is generated for the neon line. The output mimics that described previously where STD is the standard deviation and MAD is the median absolute deviation in angstroms.\n\n\nWavelength fitting for the entire slit using arcs\n\n\nThe next step in the wavelength fitting process is to propogate the arc solution spatially along each slit. Again this is the same process essentially as the fit for the night sky lines. This moves along each row for the slit to determine a wavelenth solution. The output files are comperable to those in step 8.3\n\n\nWavelength.fit_lambda(maskname, band, 'Ne.txt', 'Ne.txt', waveops, wavenames2='Ar.txt')\n\n\n\nYou will note that the Ar.txt file is listed as an optional argument. If you choose not to use the Argon lamps, then you may simply remove the optional wavenames2 and execute this using only the Ne arcs.\n\n\nAgain, this process takes some time to complete.\n\n\nMerge the arc and sky lists\n\n\nIn this portion of the procedure, we merge the two lists. These commands may not be run individually. Instead any command containing the variable LROI needs to be run in one mospy driver file session in order to pass the LROI variable. In this section we determin the offsets between the region of overlap between the nightskylines and the arclines. A plot of that region is displayed. To move on you will have to close the plot. \n\n\nTo execute this step you will need to uncomment the following lines in the driver file.\n\n\nLROI = [[21000, 22800]] * 1                                                                                                                                \nLROIs = Wavelength.check_wavelength_roi(maskname, band, obsfiles, 'Ne.txt', LROI, waveops)        \nWavelength.apply_lambda_simple(maskname, band, 'Ne.txt', waveops)                                                                                          \nWavelength.apply_lambda_sky_and_arc(maskname, band, obsfiles,  'Ne.txt', LROIs, waveops, neon=True)\n\n\n\nThe merged output solution will have a filename that looks like:\n\n\nmerged_lambda_coeffs_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.npy\nmerged_lambda_solution_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.fits\nmerged_rectified_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.fits.gz\n\n\n\nThe ouput files have the same format as those in section 8.4 and will need to be used as inputs to the Background and Rectify section below.",
            "title": "Wavelength Calibration \u2013 K Band"
        },
        {
            "location": "/wavelengthK/#wavelength-calibration-k",
            "text": "The night sky lines at the red end of the K-band are too faint to achieve small-fraction of a pixel RMS wavelength calibration. You will have to observe a Neon and Argon arc lamps during your afternoon calibrations. By default, the calibration script at the observatory is setup to acquire both the Ne and Argon arcs.  Because the beams emminating from the arclamp do not follow the same path as the beams coming from the sky, there will be a slight difference between the two solutions. For the afformentioned beam matching reason, the most accurate solution is the night sky lines. Thus, the code has to be clever about merging the two solutions.  The following subsections describe the additional steps that are necessary to process the arcline data and combine the arcs and night sky line wavelength solutions.",
            "title": "Wavelength Calibration (K)"
        },
        {
            "location": "/wavelengthK/#combine-the-arc-line-spectra",
            "text": "Just like the step in section 8.1 where you combined the science frames to create nightsky line spectra, we first need to combine the arcline data. The arcs are typically three files and you should see them listed in the Ne.txt and Ar.txt file lists in your K band sub directory. To combine the images simply uncomment and run:  Wavelength.imcombine('Ne.txt', maskname, band, waveops)                                                                                                    \nWavelength.imcombine('Ar.txt', maskname, band, waveops)",
            "title": "Combine the arc line spectra"
        },
        {
            "location": "/wavelengthK/#identify-arc-lines-using-night-sky-solution",
            "text": "Instead of having to interactively determine the wavelenth solution for the arcs like we did in section 8.2 for the night sky lines, we are going to use the solutions for the night sky lines as a first approximation for the arcs. This may usually be done because the arcs differ from the night sky lines by a fractions of pixels. You are welcome to interactively solve the neon lamp solution with the Wavelength.fit_lambda_interactively routine; however, the need to run the interactive solution method should be rare.   To apply the solution from the night sky lines to the arcs center slit position, uncomment and run the following lines.  Wavelength.apply_interactive(maskname, band, waveops, apply=obsfiles, to='Ne.txt', neon=True)                                                              \nWavelength.apply_interactive(maskname, band, waveops, apply=obsfiles, to='Ar.txt', argon=True)  This step, when run will produce output like:  slitno  1 STD: 0.16 MAD: 0.06\nslitno  2 STD: 0.03 MAD: 0.02\nslitno  3 STD: 0.04 MAD: 0.04\nslitno  4 STD: 0.05 MAD: 0.01  For each slit, a new solution is generated for the neon line. The output mimics that described previously where STD is the standard deviation and MAD is the median absolute deviation in angstroms.",
            "title": "Identify arc lines using night sky solution"
        },
        {
            "location": "/wavelengthK/#wavelength-fitting-for-the-entire-slit-using-arcs",
            "text": "The next step in the wavelength fitting process is to propogate the arc solution spatially along each slit. Again this is the same process essentially as the fit for the night sky lines. This moves along each row for the slit to determine a wavelenth solution. The output files are comperable to those in step 8.3  Wavelength.fit_lambda(maskname, band, 'Ne.txt', 'Ne.txt', waveops, wavenames2='Ar.txt')  You will note that the Ar.txt file is listed as an optional argument. If you choose not to use the Argon lamps, then you may simply remove the optional wavenames2 and execute this using only the Ne arcs.  Again, this process takes some time to complete.",
            "title": "Wavelength fitting for the entire slit using arcs"
        },
        {
            "location": "/wavelengthK/#merge-the-arc-and-sky-lists",
            "text": "In this portion of the procedure, we merge the two lists. These commands may not be run individually. Instead any command containing the variable LROI needs to be run in one mospy driver file session in order to pass the LROI variable. In this section we determin the offsets between the region of overlap between the nightskylines and the arclines. A plot of that region is displayed. To move on you will have to close the plot.   To execute this step you will need to uncomment the following lines in the driver file.  LROI = [[21000, 22800]] * 1                                                                                                                                \nLROIs = Wavelength.check_wavelength_roi(maskname, band, obsfiles, 'Ne.txt', LROI, waveops)        \nWavelength.apply_lambda_simple(maskname, band, 'Ne.txt', waveops)                                                                                          \nWavelength.apply_lambda_sky_and_arc(maskname, band, obsfiles,  'Ne.txt', LROIs, waveops, neon=True)  The merged output solution will have a filename that looks like:  merged_lambda_coeffs_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.npy\nmerged_lambda_solution_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.fits\nmerged_rectified_wave_stack_K_m130114_0451-0453_and_wave_stack_K_m140508_0197-0199.fits.gz  The ouput files have the same format as those in section 8.4 and will need to be used as inputs to the Background and Rectify section below.",
            "title": "Merge the arc and sky lists"
        },
        {
            "location": "/background/",
            "text": "Background Subtraction\n\n\nThis DRP assumes that targets are nodded along the slit with integration times as described on the instrument web page. The integration times described were selected such that the shot-noise in the region between night sky lines is over 5x larger than the read noise of a 16-fowler sample. For MOSFIRE, we define this as background limited.\n\n\nDespite MOSFIRE\u2019s (unprescedented) f/2.0 camera, the desired integration time for background-limited operation is longer than the time for the atmosphere to vary by several percent. As a result, a further background subtraction step is required to remove the residual features. The step is performed by a function called background_subtract_helper() and follows the notation and procedure outlined in Kasen (2003; PASP 115). For most users, you\u2019ll want to use the standard Driver file and not worry about the details. \n\n\nIn the Driver.py file you want to uncomment the following:\n\n\nBackground.handle_background(obsfiles, 'lambda_solution_wave_stack_J_m130114_0443-0445.fits', maskname, band, waveops)\n\n\n\nThe lambda_solution_wave_stack file needs to be updated in your driver file. If reducing Kband, be sure to use the merged wave_stack solution. It is one of the outputs from the last wavelength step (see section 8).\n\n\nIn this step:\n\n\n\n\nApply the flat field corrections \n\n\nA position files are combined (Offset_*.txt)\n\n\nB postion files are combined (Offset_-*.txt)\n\n\nSubtract A-B\n\n\nCorrect for small differences in the background sky emission\n\n\n\n\nOutput Files\n\n\nThe background subtraction step produces the following files. As usual elements in [brackets] are replaced with the value for that mask.\n\n\n\n\n\n\n\n\nFilename\n\n\nContent (units)\n\n\n\n\n\n\n\n\n\n\neps_Offset_[###].txt.fits\n\n\nAverage signal in the ### stack ()\n\n\n\n\n\n\nvar_Offset_[###].txt.fits\n\n\nTotal variance in each pixel of above file ()\n\n\n\n\n\n\nitimes_Offset_[###].txt.fits\n\n\nTotal exposure time in each pixel of above files ()\n\n\n\n\n\n\nsub_[maskname] _[bandname]_[plan].fits\n\n\nDifference (but non background subtracted) file ()\n\n\n\n\n\n\nbsub_[maskname]_{ bandname]_[plan].fits\n\n\nBackground subtracted signal ()\n\n\n\n\n\n\nbmod_[maskname]_{ bandname]_[plan].fits\n\n\nBackground model signal ()\n\n\n\n\n\n\nvar_[maskname]_{ bandname]_[plan].fits\n\n\nTotal variance\n\n\n\n\n\n\nitime_[maskname]_{ bandname]_[plan].fits\n\n\nAverage integration time\n\n\n\n\n\n\n\n\nThere is redundant information in the above set of files. For instance:\n\n\nsub_Mask_K_A-B.fits = eps_Offset_1.5.txt.fits \u2013 eps_Offset_-1.5.txt.fits\nvar_Mask_K_A-B.fits = var_Offset_1.5.txt.fits + var_Offset_1.5.txt.fits\nitime_Mask_K_A-B.fits = mean(itime_Offset_1.5.txt.fits, itime_Offset_1.5.t.xt.fits)\n\n\n\nIf you want to drill further into how these are constructed, examine the Background.py imcombine and handle_background functions.\n\n\nRecitified outputs are also computed as tabulated in the table below.\n\n\n\n\n\n\n\n\nFilename\n\n\nContent (units)\n\n\n\n\n\n\n\n\n\n\n[maskname]_rectified_[bandname]_[plan].fits\n\n\nSignal ()\n\n\n\n\n\n\n[maskname]_rectified_itime_[bandname]_[plan].fits\n\n\nIntegration time\n\n\n\n\n\n\n[maskname]_rectified_var_[bandname]_[plan].fits\n\n\nVariance\n\n\n\n\n\n\n[maskname]_rectified_sn_[bandname]_[plan].fits\n\n\nSignal to noise ()\n\n\n\n\n\n\n\n\nNote that signal to noise is computed as follows:\n\n\n\n\nyes, we violate the first normal form for convenience. Also note that the STD is computed assuming the detector has a read noise of Detector.RN (documented in the MOSFIRE Pre Ship Review as 21 electron) per fowler sample. Thus, the final STD is\n\n\n\n\nassuming the gain in Detector.gain. Note that there is no shot noise from dark current, which was measured to be negligible at pre-ship review.\n\n\nAn example of what the output looks like is here:\n\n\n\n\nImage showing the itime, bsub, and rectified wavelength images. The green crosses are marking the location of the same pixel in each image.",
            "title": "Background Subtraction"
        },
        {
            "location": "/background/#background-subtraction",
            "text": "This DRP assumes that targets are nodded along the slit with integration times as described on the instrument web page. The integration times described were selected such that the shot-noise in the region between night sky lines is over 5x larger than the read noise of a 16-fowler sample. For MOSFIRE, we define this as background limited.  Despite MOSFIRE\u2019s (unprescedented) f/2.0 camera, the desired integration time for background-limited operation is longer than the time for the atmosphere to vary by several percent. As a result, a further background subtraction step is required to remove the residual features. The step is performed by a function called background_subtract_helper() and follows the notation and procedure outlined in Kasen (2003; PASP 115). For most users, you\u2019ll want to use the standard Driver file and not worry about the details.   In the Driver.py file you want to uncomment the following:  Background.handle_background(obsfiles, 'lambda_solution_wave_stack_J_m130114_0443-0445.fits', maskname, band, waveops)  The lambda_solution_wave_stack file needs to be updated in your driver file. If reducing Kband, be sure to use the merged wave_stack solution. It is one of the outputs from the last wavelength step (see section 8).  In this step:   Apply the flat field corrections   A position files are combined (Offset_*.txt)  B postion files are combined (Offset_-*.txt)  Subtract A-B  Correct for small differences in the background sky emission",
            "title": "Background Subtraction"
        },
        {
            "location": "/background/#output-files",
            "text": "The background subtraction step produces the following files. As usual elements in [brackets] are replaced with the value for that mask.     Filename  Content (units)      eps_Offset_[###].txt.fits  Average signal in the ### stack ()    var_Offset_[###].txt.fits  Total variance in each pixel of above file ()    itimes_Offset_[###].txt.fits  Total exposure time in each pixel of above files ()    sub_[maskname] _[bandname]_[plan].fits  Difference (but non background subtracted) file ()    bsub_[maskname]_{ bandname]_[plan].fits  Background subtracted signal ()    bmod_[maskname]_{ bandname]_[plan].fits  Background model signal ()    var_[maskname]_{ bandname]_[plan].fits  Total variance    itime_[maskname]_{ bandname]_[plan].fits  Average integration time     There is redundant information in the above set of files. For instance:  sub_Mask_K_A-B.fits = eps_Offset_1.5.txt.fits \u2013 eps_Offset_-1.5.txt.fits\nvar_Mask_K_A-B.fits = var_Offset_1.5.txt.fits + var_Offset_1.5.txt.fits\nitime_Mask_K_A-B.fits = mean(itime_Offset_1.5.txt.fits, itime_Offset_1.5.t.xt.fits)  If you want to drill further into how these are constructed, examine the Background.py imcombine and handle_background functions.  Recitified outputs are also computed as tabulated in the table below.     Filename  Content (units)      [maskname]_rectified_[bandname]_[plan].fits  Signal ()    [maskname]_rectified_itime_[bandname]_[plan].fits  Integration time    [maskname]_rectified_var_[bandname]_[plan].fits  Variance    [maskname]_rectified_sn_[bandname]_[plan].fits  Signal to noise ()     Note that signal to noise is computed as follows:   yes, we violate the first normal form for convenience. Also note that the STD is computed assuming the detector has a read noise of Detector.RN (documented in the MOSFIRE Pre Ship Review as 21 electron) per fowler sample. Thus, the final STD is   assuming the gain in Detector.gain. Note that there is no shot noise from dark current, which was measured to be negligible at pre-ship review.  An example of what the output looks like is here:   Image showing the itime, bsub, and rectified wavelength images. The green crosses are marking the location of the same pixel in each image.",
            "title": "Output Files"
        },
        {
            "location": "/rectify/",
            "text": "Rectify\n\n\nThe next step in the reduction process is to combine the wavelength solution with the backgroun subtracted images and then shift and combine the nod positions. If reducing Kband, be sure to use the merged wave_stack solution.  To do this we uncomment the following lines in the Driver.py file:\n\n\nredfiles = [\"eps_\" + file + \".fits\" for file in obsfiles]\nRectify.handle_rectification(maskname, redfiles,\n    'lambda_solution_wave_stack_J_m130114_0443-0445.fits',\n    band,\n    waveops)\n\n\n\nThe output from this procedure produces four files for every slit.\n\n\n\n\n\n\n\n\nFilename\n\n\nContent (units)\n\n\n\n\n\n\n\n\n\n\n[maskname]_[band]_[object]_eps.fits\n\n\nSignal ()\n\n\n\n\n\n\n[maskname]_[band]_[object]_itime.fits\n\n\nIntegration time\n\n\n\n\n\n\n[maskname]_[band]_[object]_sig.fits\n\n\nVariance  ?\n\n\n\n\n\n\n[maskname]_[band]_{object}_snrs.fits\n\n\nSignal to noise ()\n\n\n\n\n\n\n\n\nThere is also four images without the \u201cobject\u201d in the name. These four files contain the composit spectra with all spectra aligned spectrally and both beams combined. In the *eps.fits files, you will see two negative traces and one positive trace.  For a two position nod, the eps files is (A-B) +((B-A)shifted).\n\n\nWhen extracting the emission from an object or measuring the position of an emission line, you should be accessing the *eps.fits files with the wavelength solution written into the WCS information.",
            "title": "Rectify"
        },
        {
            "location": "/rectify/#rectify",
            "text": "The next step in the reduction process is to combine the wavelength solution with the backgroun subtracted images and then shift and combine the nod positions. If reducing Kband, be sure to use the merged wave_stack solution.  To do this we uncomment the following lines in the Driver.py file:  redfiles = [\"eps_\" + file + \".fits\" for file in obsfiles]\nRectify.handle_rectification(maskname, redfiles,\n    'lambda_solution_wave_stack_J_m130114_0443-0445.fits',\n    band,\n    waveops)  The output from this procedure produces four files for every slit.     Filename  Content (units)      [maskname]_[band]_[object]_eps.fits  Signal ()    [maskname]_[band]_[object]_itime.fits  Integration time    [maskname]_[band]_[object]_sig.fits  Variance  ?    [maskname]_[band]_{object}_snrs.fits  Signal to noise ()     There is also four images without the \u201cobject\u201d in the name. These four files contain the composit spectra with all spectra aligned spectrally and both beams combined. In the *eps.fits files, you will see two negative traces and one positive trace.  For a two position nod, the eps files is (A-B) +((B-A)shifted).  When extracting the emission from an object or measuring the position of an emission line, you should be accessing the *eps.fits files with the wavelength solution written into the WCS information.",
            "title": "Rectify"
        },
        {
            "location": "/extract/",
            "text": "Spectral Extraction\n\n\nInteractive Spectral Extraction Instructions\n\n\nThe final step is to extract a 1D spectrum for each object in each slit.  The final line of the \nDriver.py\n (or equivalent) file will looks something like this:\n\n\nExtract.extract_spectra(maskname, band, interactive=(not bypassflag))\n\n\n\n\nThis will iterate through all the slits for this mask-band combination and if the interactive flag is set, then it will show a plot of the spatial profile of each slit (collapsed in the spectral direction).  By default, the software will make a guess at one aperture for each slit.  The apertures are indicated by a yellow shaded region and their center position and half width in pixels is annotated near the top of each shaded region.\n\n\n\n\nThe apertures define the pixels which will be used as input to the optimal spectral extraction (Horne 1986) algorithm.  Having wide a wide aperture should not add additional noise as that will be optimized during the spectral extraction step.  The apertures are shown here in order for the user to verify 1) that there is no overlap between adjacent objects, 2) that the apertures are wide enough to reasonably encompass all flux from the object, and 3) that all objects have properly defined apertures.\n\n\nThe user can add, modify, or delete apertures interactively using this plot window.\n\n\nTo delete an existing aperture: place the mouse near the center of the aperture and press the \"d\" key.\n\n\nTo add an aperture by fitting a gaussian to the profile: place the mouse near the peak of the profile and press the \"g\" key.  The half width of the aperture will be set at 5 times the sigma of the fitted gaussian.\n\n\n\n\nTo add an aperture manually: place the mouse in the X position where the new aperture should be centered and press the \"a\" key.  Then type the half width (in pixels) for that aperture in response to the query in the terminal.\n\n\nTo modify the half width of an existing aperture: place the mouse near the center of the aperture and press the \"w\" key.  Then type the half width (in pixels) for that aperture in response to the query in the terminal.\n\n\nTo modify the center position of an existing aperture: place the mouse near the center of the aperture and press the \"p\" key.  Then type the position (in pixels) for that aperture in response to the query in the terminal.\n\n\nWhen you are done adding or removing apertures, close the interactive plot window by clicking the close button in the upper right corner (or by whatever method is typical for your OS or windowing system) or press the \"q\" or \"n\" keys (for \"quit\" or \"next\" respectively).\n\n\nSpectral Extraction Results\n\n\nWhether you used the interactive tool for spectral extraction or allowed the software to automatically guess at the apertures to extract, the software will output both a FITS version of the resulting 1D spectrum and an PNG plot.\n\n\nThese filenames will have the form:\n\n\n[maskname]_[band]_[targetname]_[aperture].png\n[maskname]_[band]_[targetname]_1D_[aperture].fits\n\n\n\n\nwhere \n[aperture]\n is a two digit integer indication which aperture for that slit this corresponds to (zero based).  If the apertures were determined automatically by the software, then only one aperture will have been generated for each slit, so all files will end in \n_00.png\n or \n_1D_00.fits\n.",
            "title": "Spectral Extraction"
        },
        {
            "location": "/extract/#spectral-extraction",
            "text": "",
            "title": "Spectral Extraction"
        },
        {
            "location": "/extract/#interactive-spectral-extraction-instructions",
            "text": "The final step is to extract a 1D spectrum for each object in each slit.  The final line of the  Driver.py  (or equivalent) file will looks something like this:  Extract.extract_spectra(maskname, band, interactive=(not bypassflag))  This will iterate through all the slits for this mask-band combination and if the interactive flag is set, then it will show a plot of the spatial profile of each slit (collapsed in the spectral direction).  By default, the software will make a guess at one aperture for each slit.  The apertures are indicated by a yellow shaded region and their center position and half width in pixels is annotated near the top of each shaded region.   The apertures define the pixels which will be used as input to the optimal spectral extraction (Horne 1986) algorithm.  Having wide a wide aperture should not add additional noise as that will be optimized during the spectral extraction step.  The apertures are shown here in order for the user to verify 1) that there is no overlap between adjacent objects, 2) that the apertures are wide enough to reasonably encompass all flux from the object, and 3) that all objects have properly defined apertures.  The user can add, modify, or delete apertures interactively using this plot window.  To delete an existing aperture: place the mouse near the center of the aperture and press the \"d\" key.  To add an aperture by fitting a gaussian to the profile: place the mouse near the peak of the profile and press the \"g\" key.  The half width of the aperture will be set at 5 times the sigma of the fitted gaussian.   To add an aperture manually: place the mouse in the X position where the new aperture should be centered and press the \"a\" key.  Then type the half width (in pixels) for that aperture in response to the query in the terminal.  To modify the half width of an existing aperture: place the mouse near the center of the aperture and press the \"w\" key.  Then type the half width (in pixels) for that aperture in response to the query in the terminal.  To modify the center position of an existing aperture: place the mouse near the center of the aperture and press the \"p\" key.  Then type the position (in pixels) for that aperture in response to the query in the terminal.  When you are done adding or removing apertures, close the interactive plot window by clicking the close button in the upper right corner (or by whatever method is typical for your OS or windowing system) or press the \"q\" or \"n\" keys (for \"quit\" or \"next\" respectively).",
            "title": "Interactive Spectral Extraction Instructions"
        },
        {
            "location": "/extract/#spectral-extraction-results",
            "text": "Whether you used the interactive tool for spectral extraction or allowed the software to automatically guess at the apertures to extract, the software will output both a FITS version of the resulting 1D spectrum and an PNG plot.  These filenames will have the form:  [maskname]_[band]_[targetname]_[aperture].png\n[maskname]_[band]_[targetname]_1D_[aperture].fits  where  [aperture]  is a two digit integer indication which aperture for that slit this corresponds to (zero based).  If the apertures were determined automatically by the software, then only one aperture will have been generated for each slit, so all files will end in  _00.png  or  _1D_00.fits .",
            "title": "Spectral Extraction Results"
        },
        {
            "location": "/long2pos/",
            "text": "Long2pos Reductions\n\n\nA special driver is provided for long2pos reductions. The driver can also be generated automatically.\n\n\nAs s reminder, these observations are taken using a script which is run either from the command line (acq_long2pos) or via the background menu. The script produces different results depending on whether the long2pos mask was setup in science mode (only narrow slits) or in alignment mode (narrow and wide slits).\n\n\nIn the general case of a combination of narrow and wide slits, each run of the script generates 6 images, 3 for each of the two slits. We will refer to the two positions as position A and position C (position B is the intial position used only for alignment).\n\n\nDepending on when your data was generated, you might find different Offset files in your directory. Files generated before June 10, 2015 use a different set of YOFFSET keywords than files generated after that date. Unfortunately, the set of keywords generated before June 10, 2015 is not compatible with the pipeline and must be updated: for this we provide a special set of instructions as part of as the driver file to automatically update the keywords.\n\n\nFor files generated before June 10, 2015, you will find 6 Offset files, named Offset_XXX_object_name_PosY.txt, where XXX can be -21, -14,-7, 7, 14 and 21, the object name is taken from the object keyword, and Y can be either A or C. Similar names are produced if the observations has the correct keywords, but in that case XXX will be one of -7, 0, or 7.\n\n\nIt is important to notice that the reduction described here is based on the assumption that proper arc lamps are obtained in the afternoon. Specifically, either a Ne or Ar calibration must be obtained with the long2pos mask executed in science mode, and not in alignment mode. In science mode the wide part of the slits is not present. If the slit was executed in alignment mode, the wide part of the slits would prevent a wavelength calibration.\n\n\nNote that this also means that if you took your science data at night in long2pos_specphot mode, the mask name of your science file might be long2pos_specphot, rather than long2pos, and the arcs and flats might end up in the wrong subdirectory when the files are processed via mospy handle. In this case it will be necessary to copy Ar.txt, Ne.txt and Flat*.txt from the directory long2pos to your long2pos_specphot directory.\n\n\nLet\u2019s now look at the driver file.  The declaration \"longslit =\" is used to define the pixel boundaries of the long2pos observations. In general, it is correct and should not be changed. It might need to be updated in the future is a new long2pos mask is used. Note that it is important to specify \u2018mode\u2019=\u2019long2pos\u2019\n\n\nThe following section describes the rather long list of Offset files that we will use for the reduction.\n\n\nFor observations obtained before June 10, 2015, this section might look like this:\n\n\nobsfiles_posC_narrow = ['Offset_-21_HIP85871_PosC.txt', 'Offset_-7_HIP85871_PosC.txt']\ntargetCnarrow = \"HIP85871_posC_narrow\"\n\nobsfiles_posA_narrow = ['Offset_7_HIP85871_PosA.txt', 'Offset_21_HIP85871_PosA.txt']\ntargetAnarrow = \"HIP85871_posA_narrow\"\n\nobsfiles_posC_wide = ['Offset_-14_HIP85871_PosC.txt','Offset_-7_HIP85871_PosC.txt']\ntargetCwide = \"HIP85871_posC_wide\"\n\nobsfiles_posA_wide = ['Offset_14_HIP85871_PosA.txt','Offset_21_HIP85871_PosA.txt']\ntargetAwide = \"HIP85871_posA_wide\"\n\n\n\nFiles -21_PosC and -7_PosC are the A and B positions for the C pointing, files 7 and 21 are the A and B positions for the A pointing. For the wise slits, file 7_PosC is used as a sky (B) for the -14_PosC position, and file 21_PosA is used as a sky for the 14_PosA position. The target keywords must also be specified to avoid accidental overwrite of intermediate files.\n\n\nFor files obtained after June 10, 2015, the same section would look like this:\n\n\nobsfiles_posC_narrow = ['Offset_7_FS134_posC.txt','Offset_-7_FS134_PosC.txt']\ntargetCnarrow = \"FS134_posC_narrow\"\nobsfiles_posA_narrow = ['Offset_7_FS134_posA.txt','Offset_-7_FS134_PosA.txt']\ntargetAnarrow = \"FS134_posA_narrow\"\nobsfiles_posC_wide = ['Offset_0_FS134_posC.txt','Offset_-7_FS134_PosC.txt']\ntargetCwide = \"FS134_posC_wide\"\nobsfiles_posA_wide = ['Offset_0_FS134_posA.txt','Offset_-7_FS134_PosA.txt']\ntargetAwide = \"FS134_posA_wide\"\n\n\n\nThe first step is to produce a flat field.\n\n\nFlats.handle_flats('Flat.txt', maskname, band, flatops, longslit = longslit)\n\n\n\nor\n\n\nFlats.handle_flats('Flat.txt', maskname, band, flatops,lampOffList='FlatThermal.txt', longslit=longslit)\n\n\n\nUsing argon (or neon) lines, we can now produce a wavelength calibration.\n\n\nWavelength.imcombine(argon, maskname, band, waveops)\nWavelength.fit_lambda_interactively(maskname, band, argon, waveops, longslit=longslit, argon=True)\nWavelength.fit_lambda(maskname, band, argon, argon, waveops, longslit=longslit)\nWavelength.apply_lambda_simple(maskname, band, argon, waveops, longslit=longslit, smooth=True)\n\n\n\nWhile using the interactive fitting, note that there are two slits to fit.\n\n\nThe next section of the driver reduces the narrow slits. The optional line \n\n\nIO.fix_long2pos_headers(obsfiles)\n\n\n\nis ONLY necessary if your observations were taken before June 10, 2015. It is safe to leave this line on for a second run: the script will not modify the same files twice.\n\n\nRememeber to update the lambda_solution_wave_stack file: you can update this in the variable wavelength_file, which will be used by the following instructions.\n\n\nThe driver contains instructions on how to perform background subtraction and finally rectification, in a similar way as for a normal mask.\n\n\nThe resulting files are the same as in the standard reduction, but the main results are contained in:\n\n\n{object}_posA_narrow_{filter}_eps.fits\n\n\n\nand \n\n\n{object}_posC_narrow_{filter}_eps.fits\n\n\n\nFor the wide slits, since there is no AB pattern, we use the sky provided by one of the observations in the narrow slits, and we do not perform the final rectification.\n\n\nIn this case the final science results are contained in:\n\n\nbsub_{object}_posC_wide_{filter}_A-B.fits\n\n\n\nand\n\n\nbsub_{object}_posA_wide_{filter}_A-B.fits",
            "title": "Long2pos Reductions"
        },
        {
            "location": "/long2pos/#long2pos-reductions",
            "text": "A special driver is provided for long2pos reductions. The driver can also be generated automatically.  As s reminder, these observations are taken using a script which is run either from the command line (acq_long2pos) or via the background menu. The script produces different results depending on whether the long2pos mask was setup in science mode (only narrow slits) or in alignment mode (narrow and wide slits).  In the general case of a combination of narrow and wide slits, each run of the script generates 6 images, 3 for each of the two slits. We will refer to the two positions as position A and position C (position B is the intial position used only for alignment).  Depending on when your data was generated, you might find different Offset files in your directory. Files generated before June 10, 2015 use a different set of YOFFSET keywords than files generated after that date. Unfortunately, the set of keywords generated before June 10, 2015 is not compatible with the pipeline and must be updated: for this we provide a special set of instructions as part of as the driver file to automatically update the keywords.  For files generated before June 10, 2015, you will find 6 Offset files, named Offset_XXX_object_name_PosY.txt, where XXX can be -21, -14,-7, 7, 14 and 21, the object name is taken from the object keyword, and Y can be either A or C. Similar names are produced if the observations has the correct keywords, but in that case XXX will be one of -7, 0, or 7.  It is important to notice that the reduction described here is based on the assumption that proper arc lamps are obtained in the afternoon. Specifically, either a Ne or Ar calibration must be obtained with the long2pos mask executed in science mode, and not in alignment mode. In science mode the wide part of the slits is not present. If the slit was executed in alignment mode, the wide part of the slits would prevent a wavelength calibration.  Note that this also means that if you took your science data at night in long2pos_specphot mode, the mask name of your science file might be long2pos_specphot, rather than long2pos, and the arcs and flats might end up in the wrong subdirectory when the files are processed via mospy handle. In this case it will be necessary to copy Ar.txt, Ne.txt and Flat*.txt from the directory long2pos to your long2pos_specphot directory.  Let\u2019s now look at the driver file.  The declaration \"longslit =\" is used to define the pixel boundaries of the long2pos observations. In general, it is correct and should not be changed. It might need to be updated in the future is a new long2pos mask is used. Note that it is important to specify \u2018mode\u2019=\u2019long2pos\u2019  The following section describes the rather long list of Offset files that we will use for the reduction.  For observations obtained before June 10, 2015, this section might look like this:  obsfiles_posC_narrow = ['Offset_-21_HIP85871_PosC.txt', 'Offset_-7_HIP85871_PosC.txt']\ntargetCnarrow = \"HIP85871_posC_narrow\"\n\nobsfiles_posA_narrow = ['Offset_7_HIP85871_PosA.txt', 'Offset_21_HIP85871_PosA.txt']\ntargetAnarrow = \"HIP85871_posA_narrow\"\n\nobsfiles_posC_wide = ['Offset_-14_HIP85871_PosC.txt','Offset_-7_HIP85871_PosC.txt']\ntargetCwide = \"HIP85871_posC_wide\"\n\nobsfiles_posA_wide = ['Offset_14_HIP85871_PosA.txt','Offset_21_HIP85871_PosA.txt']\ntargetAwide = \"HIP85871_posA_wide\"  Files -21_PosC and -7_PosC are the A and B positions for the C pointing, files 7 and 21 are the A and B positions for the A pointing. For the wise slits, file 7_PosC is used as a sky (B) for the -14_PosC position, and file 21_PosA is used as a sky for the 14_PosA position. The target keywords must also be specified to avoid accidental overwrite of intermediate files.  For files obtained after June 10, 2015, the same section would look like this:  obsfiles_posC_narrow = ['Offset_7_FS134_posC.txt','Offset_-7_FS134_PosC.txt']\ntargetCnarrow = \"FS134_posC_narrow\"\nobsfiles_posA_narrow = ['Offset_7_FS134_posA.txt','Offset_-7_FS134_PosA.txt']\ntargetAnarrow = \"FS134_posA_narrow\"\nobsfiles_posC_wide = ['Offset_0_FS134_posC.txt','Offset_-7_FS134_PosC.txt']\ntargetCwide = \"FS134_posC_wide\"\nobsfiles_posA_wide = ['Offset_0_FS134_posA.txt','Offset_-7_FS134_PosA.txt']\ntargetAwide = \"FS134_posA_wide\"  The first step is to produce a flat field.  Flats.handle_flats('Flat.txt', maskname, band, flatops, longslit = longslit)  or  Flats.handle_flats('Flat.txt', maskname, band, flatops,lampOffList='FlatThermal.txt', longslit=longslit)  Using argon (or neon) lines, we can now produce a wavelength calibration.  Wavelength.imcombine(argon, maskname, band, waveops)\nWavelength.fit_lambda_interactively(maskname, band, argon, waveops, longslit=longslit, argon=True)\nWavelength.fit_lambda(maskname, band, argon, argon, waveops, longslit=longslit)\nWavelength.apply_lambda_simple(maskname, band, argon, waveops, longslit=longslit, smooth=True)  While using the interactive fitting, note that there are two slits to fit.  The next section of the driver reduces the narrow slits. The optional line   IO.fix_long2pos_headers(obsfiles)  is ONLY necessary if your observations were taken before June 10, 2015. It is safe to leave this line on for a second run: the script will not modify the same files twice.  Rememeber to update the lambda_solution_wave_stack file: you can update this in the variable wavelength_file, which will be used by the following instructions.  The driver contains instructions on how to perform background subtraction and finally rectification, in a similar way as for a normal mask.  The resulting files are the same as in the standard reduction, but the main results are contained in:  {object}_posA_narrow_{filter}_eps.fits  and   {object}_posC_narrow_{filter}_eps.fits  For the wide slits, since there is no AB pattern, we use the sky provided by one of the observations in the narrow slits, and we do not perform the final rectification.  In this case the final science results are contained in:  bsub_{object}_posC_wide_{filter}_A-B.fits  and  bsub_{object}_posA_wide_{filter}_A-B.fits",
            "title": "Long2pos Reductions"
        },
        {
            "location": "/longslit/",
            "text": "Longslit Reductions\n\n\nThe longslit reductions require transferring the Longslit_Driver.py file into the reduction directory. A few key parameters have to be adjusted in Longslit_Driver.py to help the pipeline figure out where to extract the longslit from. \n\n\n\n\ncd /path/to/LONGSLIT/\n\n\ncp ~/MosfireDRP-master/drivers/Longslit_driver.py .\n\n\nCheck all the .txt files to make sure your observations are included. You may have to merge files from various LONGSLIT* directories. This happens when your observations use a shorter longslit than the calibrations. \n\n\nNote that mospy handle generates separate offset files for each of your targets, using the target name, but does NOT separate repeated observations of the same targets at different times of the night.\n\n\nedit \nDriver_Longslit.py\n\n\nExamine a longslit image (see figure below) and adjust 'yrange': [709, 1350] to the vertical range covered by the slit\n\n\nFrom the same examined longslit, select \u2018row_position\u2019 so that it is uncontaminated by the spectrum. See Figure 1.\n\n\nmake sure that \u2018mode\u2019:\u2019longslit\u2019 is specified in the longslit variable\n\n\nThe result should look like Figure 2.\n\n\n\n\n\n\nFor each step in a section, uncomment the necessary line and run mosdrp on the Driver file. Once the apply_lambda_simple step is complete, fill in the 'lambda_solution_wave_stack_...' line with the correct wave stack file.\n\n\n\n\nYou now have two options based on the results. If the night sky lines are not bright enough to identify in the interactive step you should use arclamps. In the following instructions, replace wavefiles with \u2018Ne.txt\u2019 or \u2018Ar.txt\u2019 and specify neon=True or argon=True.\n\n\n\n\nAn example of an uncontaminated row (#1127) in the longslit.\n\n\n\n\nExample of a modified Driver_Longslit.py. Notice that pixel 991 is selected as the row to perform the initial wavelength solution on. In Figure 2, this is the equivalent of 1127.",
            "title": "Longslit Reductions"
        },
        {
            "location": "/longslit/#longslit-reductions",
            "text": "The longslit reductions require transferring the Longslit_Driver.py file into the reduction directory. A few key parameters have to be adjusted in Longslit_Driver.py to help the pipeline figure out where to extract the longslit from.    cd /path/to/LONGSLIT/  cp ~/MosfireDRP-master/drivers/Longslit_driver.py .  Check all the .txt files to make sure your observations are included. You may have to merge files from various LONGSLIT* directories. This happens when your observations use a shorter longslit than the calibrations.   Note that mospy handle generates separate offset files for each of your targets, using the target name, but does NOT separate repeated observations of the same targets at different times of the night.  edit  Driver_Longslit.py  Examine a longslit image (see figure below) and adjust 'yrange': [709, 1350] to the vertical range covered by the slit  From the same examined longslit, select \u2018row_position\u2019 so that it is uncontaminated by the spectrum. See Figure 1.  make sure that \u2018mode\u2019:\u2019longslit\u2019 is specified in the longslit variable  The result should look like Figure 2.    For each step in a section, uncomment the necessary line and run mosdrp on the Driver file. Once the apply_lambda_simple step is complete, fill in the 'lambda_solution_wave_stack_...' line with the correct wave stack file.   You now have two options based on the results. If the night sky lines are not bright enough to identify in the interactive step you should use arclamps. In the following instructions, replace wavefiles with \u2018Ne.txt\u2019 or \u2018Ar.txt\u2019 and specify neon=True or argon=True.   An example of an uncontaminated row (#1127) in the longslit.   Example of a modified Driver_Longslit.py. Notice that pixel 991 is selected as the row to perform the initial wavelength solution on. In Figure 2, this is the equivalent of 1127.",
            "title": "Longslit Reductions"
        },
        {
            "location": "/headercomments/",
            "text": "Header Comments\n\n\nFiles produced by the DRP have a series of information in the FITS header that helps users determine the pedigree of files involved in the reduction. Since many files go into reductions, FITS headers are enormous and some documentation about them is useful.\n\n\nThe derived product FITS headers are organized as follows. The header of the first science file in the \u2018A\u2019 frame goes directly into the header. As the rest of the \u2018A\u2019 frames go into the header, the new keyword is checked against the current header. If the value of the keyword is different, a new keyword is added with the key postpended by _img### where ### is the file number. A special keyword called imfno### is created showing the full path to the file in the data reduction set. An example is shown below:\n\n\n![Screenshot](image9.png \"ds9 output of the FITS header. Note that the first \"A\" frame file is located in /scr2/mosfire/2013nov26/m131126_0135.fits. The second file (#137) has a similar path. The keywords which follow from file #137 have different values than those in file #135 and are thus named KEY_img###.\")\n\n\nds9 output of the FITS header. Note that the first \"A\" frame file is located in /scr2/mosfire/2013nov26/m131126_0135.fits. The second file (#137) has a similar path. The keywords which follow from file #137 have different values than those in file #135 and are thus named KEY_img###.",
            "title": "A Word About Header Comments"
        },
        {
            "location": "/headercomments/#header-comments",
            "text": "Files produced by the DRP have a series of information in the FITS header that helps users determine the pedigree of files involved in the reduction. Since many files go into reductions, FITS headers are enormous and some documentation about them is useful.  The derived product FITS headers are organized as follows. The header of the first science file in the \u2018A\u2019 frame goes directly into the header. As the rest of the \u2018A\u2019 frames go into the header, the new keyword is checked against the current header. If the value of the keyword is different, a new keyword is added with the key postpended by _img### where ### is the file number. A special keyword called imfno### is created showing the full path to the file in the data reduction set. An example is shown below:  ![Screenshot](image9.png \"ds9 output of the FITS header. Note that the first \"A\" frame file is located in /scr2/mosfire/2013nov26/m131126_0135.fits. The second file (#137) has a similar path. The keywords which follow from file #137 have different values than those in file #135 and are thus named KEY_img###.\")  ds9 output of the FITS header. Note that the first \"A\" frame file is located in /scr2/mosfire/2013nov26/m131126_0135.fits. The second file (#137) has a similar path. The keywords which follow from file #137 have different values than those in file #135 and are thus named KEY_img###.",
            "title": "Header Comments"
        },
        {
            "location": "/hints/",
            "text": "Hints\n\n\nPay attention to the wavelength fitting output\n\n\n\n\nThe output above shows that up to pixel 1015 the RMS was 0.27 Angstrom level, and then dramatically jumped to 60 angstrom. Look at the image and examine pixel 1016, figure out what happened. You may have to adjust your input files or remove a file from the set.\n\n\nLook at rectified_wave_stack files\n\n\nLook at rectified_wave_stack* files and make sure the night sky lines are vertical on the detector.",
            "title": "Some Hints"
        },
        {
            "location": "/hints/#hints",
            "text": "",
            "title": "Hints"
        },
        {
            "location": "/hints/#pay-attention-to-the-wavelength-fitting-output",
            "text": "The output above shows that up to pixel 1015 the RMS was 0.27 Angstrom level, and then dramatically jumped to 60 angstrom. Look at the image and examine pixel 1016, figure out what happened. You may have to adjust your input files or remove a file from the set.",
            "title": "Pay attention to the wavelength fitting output"
        },
        {
            "location": "/hints/#look-at-rectified_wave_stack-files",
            "text": "Look at rectified_wave_stack* files and make sure the night sky lines are vertical on the detector.",
            "title": "Look at rectified_wave_stack files"
        }
    ]
}